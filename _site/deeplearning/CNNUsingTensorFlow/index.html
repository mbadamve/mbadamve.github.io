<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.22.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>How to classify ship images with Deep Learning -</title>
<meta name="description" content="The goal of this project is to create a Deep Learning model using Convolutional Neural Networks. The dataset consists of images of 5 types of ships which are labeled {‘Cargo’: 1, ‘Military’: 2, ‘Carrier’: 3, ‘Cruise’: 4, ‘Tankers’: 5}. The Convolutional Neural Network (CNN) is trained with the images of all these types of ships using a 60% of the data and validated simulataneously against 20% of the data and finally test the trained model with the remaining 20% of the data. The model is adjusted with various hyperparameters like using different activation functions, loss functions, changing the epochs, using different neural network initializing methods, changing network size and number of layers and finally obtaining the best accurate version of the CNN for the data. The programming is done in TensorFlow API by Google and the ‘loss and accuracy’ plot indicates how good or bad the network is trained aganist the data.">


  <meta name="author" content="Mahesh Badam">
  
  <meta property="article:author" content="Mahesh Badam">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="">
<meta property="og:title" content="How to classify ship images with Deep Learning">
<meta property="og:url" content="http://localhost:4000/deeplearning/CNNUsingTensorFlow/">


  <meta property="og:description" content="The goal of this project is to create a Deep Learning model using Convolutional Neural Networks. The dataset consists of images of 5 types of ships which are labeled {‘Cargo’: 1, ‘Military’: 2, ‘Carrier’: 3, ‘Cruise’: 4, ‘Tankers’: 5}. The Convolutional Neural Network (CNN) is trained with the images of all these types of ships using a 60% of the data and validated simulataneously against 20% of the data and finally test the trained model with the remaining 20% of the data. The model is adjusted with various hyperparameters like using different activation functions, loss functions, changing the epochs, using different neural network initializing methods, changing network size and number of layers and finally obtaining the best accurate version of the CNN for the data. The programming is done in TensorFlow API by Google and the ‘loss and accuracy’ plot indicates how good or bad the network is trained aganist the data.">







  <meta property="article:published_time" content="2021-03-30T00:00:00-04:00">





  

  


<link rel="canonical" href="http://localhost:4000/deeplearning/CNNUsingTensorFlow/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Mahesh Badam",
      "url": "http://localhost:4000/"
    
  }
</script>






<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title=" Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css">

<!--[if IE]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->


    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/"><img src="/assets/images/site-logo.png" alt=""></a>
        
        <a class="site-title" href="/">
          
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/about/">About</a>
            </li><li class="masthead__menu-item">
              <a href="/projects/">Projects</a>
            </li><li class="masthead__menu-item">
              <a href="/categories/">Categories</a>
            </li><li class="masthead__menu-item">
              <a href="/tags/">Tags</a>
            </li><li class="masthead__menu-item">
              <a href="/resume/">Resume</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
    
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  
    <div class="author__avatar">
      
        <img src="/assets/images/My-Pic.jpg" alt="Mahesh Badam" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">Mahesh Badam</h3>
    
    
      <div class="author__bio" itemprop="description">
        <p>I’m a graduate student at Syracuse University majoring in Applied Data Science</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name">Syracuse, NY, USA</span>
        </li>
      

      
        
          
            <li><a href="mailto:maheshbadam945@gmail.com" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span></a></li>
          
        
          
        
          
        
          
        
          
            <li><a href="https://github.com/mbadamve" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
            <li><a href="https://linkedin.com/in/mahesh-badam" rel="nofollow noopener noreferrer"><i class="fab fa-linkedin" aria-hidden="true"></i><span class="label">LinkedIn</span></a></li>
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>



    <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
        
        <meta itemprop="headline" content="How to classify ship images with Deep Learning">
        
        
        <meta itemprop="description"
            content="The goal of this project is to create a Deep Learning model using Convolutional Neural Networks. The dataset consists of images of 5 types of ships which are labeled {‘Cargo’: 1, ‘Military’: 2, ‘Carrier’: 3, ‘Cruise’: 4, ‘Tankers’: 5}. The Convolutional Neural Network (CNN) is trained with the images of all these types of ships using a 60% of the data and validated simulataneously against 20% of the data and finally test the trained model with the remaining 20% of the data. The model is adjusted with various hyperparameters like using different activation functions, loss functions, changing the epochs, using different neural network initializing methods, changing network size and number of layers and finally obtaining the best accurate version of the CNN for the data. The programming is done in TensorFlow API by Google and the ‘loss and accuracy’ plot indicates how good or bad the network is trained aganist the data.">
        
        <meta itemprop="datePublished" content="2021-03-30T00:00:00-04:00">
        

        <div class="page__inner-wrap">
            
            <header>
                <h1 id="page-title" class="page__title" itemprop="headline">How to classify ship images with Deep Learning
</h1>
                

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          31 minute read
        
      </span>
    
  </p>


            </header>
            

            <section class="page__content" itemprop="text">
                
                <aside class="sidebar__right ">
                    <nav class="toc">
                        <header>
                            <h4 class="nav__title"><i class="fas fa-clone"></i> Table of Contents</h4>
                        </header>
                        <ul class="toc__menu"><li><a href="#problem-statement">Problem Statement</a></li><li><a href="#data-introduction">Data Introduction</a></li><li><a href="#solution-approach">Solution Approach</a></li><li><a href="#dependencies">Dependencies</a></li><li><a href="#lets-import-libraries">Let’s import libraries</a></li><li><a href="#loading-the-data">Loading the Data</a></li><li><a href="#splitting-the-data-into-training-and-testing-dataset">Splitting the data into training and testing dataset.</a></li><li><a href="#data-preprocessing">Data Preprocessing</a></li><li><a href="#the-images-data-is-then-split-into-training-validation-and-testing-sets">The images data is then split into training, validation and testing sets</a></li><li><a href="#defining-four-functions">Defining four functions</a></li><li><a href="#the-cnn-model-1">The CNN Model 1:</a></li><li><a href="#another-activation-function">Another Activation function</a></li><li><a href="#conclusion">Conclusion</a></li></ul>

                    </nav>
                </aside>
                
                <p>The goal of this project is to create a Deep Learning model using Convolutional Neural Networks. The dataset consists of images of 5 types of ships which are labeled {‘Cargo’: 1, ‘Military’: 2, ‘Carrier’: 3, ‘Cruise’: 4, ‘Tankers’: 5}. The Convolutional Neural Network (CNN) is trained with the images of all these types of ships using a 60% of the data and validated simulataneously against 20% of the data and finally test the trained model with the remaining 20% of the data. The model is adjusted with various hyperparameters like using different activation functions, loss functions, changing the epochs, using different neural network initializing methods, changing network size and number of layers and finally obtaining the best accurate version of the CNN for the data. The programming is done in TensorFlow API by Google and the ‘loss and accuracy’ plot indicates how good or bad the network is trained aganist the data.</p>

<h3 id="problem-statement">Problem Statement</h3>

<p>Develop a Deep Learning model that automatically classifies the type of the ship when one or more images are given as input. The data can be obtained from this <a href="https://www.kaggle.com/arpitjain007/game-of-deep-learning-ship-datasets">link</a></p>

<h3 id="data-introduction">Data Introduction</h3>
<p>The ships dataset from kaggle has around 6252 images which are randomly split into train and test sets for the neural network. The categories of ships and their corresponding codes in the dataset are as follows - {‘Cargo’: 1, ‘Military’: 2, ‘Carrier’: 3, ‘Cruise’: 4, ‘Tankers’: 5}</p>

<h3 id="solution-approach">Solution Approach</h3>
<ol>
  <li>Firstly, the csv file which has the image name and category of the image is converted to a pandas dataframe and then split into training and testing dataframes.</li>
  <li>Secondly, the images using the names and labels in the dataframes are converted to an tuple format which specifies images as numpy n-dimensional arrays of shape (32,32) and the labels in the second part of the tuple.</li>
  <li>Thirdly, the image pixels data that is generated is fed to the neural network made of Conv2D layers, MaxPooling2D, Flatten and Dense layers with appropriate activation functions added to each layer and other methods.</li>
  <li>Finally the results are evaluated with respect to training, validation losses and accuracies to understand the behavior of the Neural Network, and choose the best conbination of the parameters as the final model.</li>
</ol>

<h3 id="dependencies">Dependencies</h3>
<ol>
  <li>TensorFlow - Refer this <a href="https://www.tensorflow.org/install/pip##system-install">link</a> for installation instructions.</li>
  <li>Scikit-learn - Installation instructions <a href="https://scikit-learn.org/stable/install.html">here</a></li>
  <li>NumPy - Installation instructions <a href="https://numpy.org/install/">here</a></li>
  <li>Pandas - Installation instructions <a href="https://pandas.pydata.org/getting_started.html">here</a></li>
  <li>Matplotlib - Installation instructions <a href="https://matplotlib.org/stable/users/installing.html">here</a></li>
</ol>

<h2 id="part-a---deep-learning-model---convolutional-neural-network-cnn">Part A - Deep Learning model - Convolutional Neural Network (CNN)</h2>

<h3 id="lets-import-libraries">Let’s import libraries</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing.image</span> <span class="kn">import</span> <span class="n">ImageDataGenerator</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span><span class="p">,</span> <span class="n">models</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">LeakyReLU</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.losses</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">Image</span>
</code></pre></div></div>

<h3 id="loading-the-data">Loading the Data</h3>

<p>It is assumed that data folder is in the same directory as this file. Hence relative path is being in the parameters.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'train.csv'</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">str</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">## Viewing the contents of the dataframe
</span>
<span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>image</th>
      <th>category</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2823080.jpg</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2870024.jpg</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2662125.jpg</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2900420.jpg</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2804883.jpg</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>

<h3 id="splitting-the-data-into-training-and-testing-dataset">Splitting the data into training and testing dataset.</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">## Sample images of ships are shown below
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">display</span><span class="p">(</span><span class="n">Image</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="mi">470</span><span class="p">,</span><span class="n">filename</span><span class="o">=</span><span class="s">'./images/'</span><span class="o">+</span><span class="n">train_data</span><span class="p">.</span><span class="n">image</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
</code></pre></div></div>

<p><img src="assets/images/output_10_0.jpg" alt="jpeg" /></p>

<p><img src="assets/images/output_10_1.jpg" alt="jpeg" /></p>

<p><img src="assets/images/output_10_2.jpg" alt="jpeg" /></p>

<p><img src="assets/images/output_10_3.jpg" alt="jpeg" /></p>

<p><img src="assets/images/output_10_4.jpg" alt="jpeg" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">"===== Images used in the training data ====="</span><span class="p">,</span> <span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"===== Images used in the testing data ====="</span><span class="p">,</span> <span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>===== Images used in the training data =====
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>image</th>
      <th>category</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>478</th>
      <td>2790315.jpg</td>
      <td>1</td>
    </tr>
    <tr>
      <th>5099</th>
      <td>2895143.jpg</td>
      <td>3</td>
    </tr>
    <tr>
      <th>1203</th>
      <td>2677725.jpg</td>
      <td>2</td>
    </tr>
    <tr>
      <th>5674</th>
      <td>2779530.jpg</td>
      <td>2</td>
    </tr>
    <tr>
      <th>142</th>
      <td>2810767.jpg</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>3772</th>
      <td>2853892.jpg</td>
      <td>1</td>
    </tr>
    <tr>
      <th>5191</th>
      <td>2903689.jpg</td>
      <td>2</td>
    </tr>
    <tr>
      <th>5226</th>
      <td>1820874.jpg</td>
      <td>4</td>
    </tr>
    <tr>
      <th>5390</th>
      <td>2884285.jpg</td>
      <td>5</td>
    </tr>
    <tr>
      <th>860</th>
      <td>2903475.jpg</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
<p>5001 rows × 2 columns</p>
</div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>===== Images used in the testing data =====
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>image</th>
      <th>category</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1703</th>
      <td>2525185.jpg</td>
      <td>4</td>
    </tr>
    <tr>
      <th>5448</th>
      <td>2837639.jpg</td>
      <td>1</td>
    </tr>
    <tr>
      <th>5058</th>
      <td>2904577.jpg</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1149</th>
      <td>2866290.jpg</td>
      <td>3</td>
    </tr>
    <tr>
      <th>432</th>
      <td>2459131.jpg</td>
      <td>4</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>416</th>
      <td>2884436.jpg</td>
      <td>5</td>
    </tr>
    <tr>
      <th>6110</th>
      <td>2782276.jpg</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3185</th>
      <td>2843694.jpg</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2025</th>
      <td>2792377.jpg</td>
      <td>1</td>
    </tr>
    <tr>
      <th>564</th>
      <td>2838422.jpg</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
<p>1251 rows × 2 columns</p>
</div>

<h3 id="data-preprocessing">Data Preprocessing</h3>
<p>Images are to be converted into (32,32) dimensional arrays using ImageDataGenerator() from TensorFlow</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_generator</span> <span class="o">=</span> <span class="n">ImageDataGenerator</span><span class="p">(</span><span class="n">rescale</span><span class="o">=</span><span class="mf">1.</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="the-images-data-is-then-split-into-training-validation-and-testing-sets">The images data is then split into training, validation and testing sets</h3>

<p>What happens here is, the names of the images are in the dataframe and we give the dataframe as the arguemnt to the data_generator.flow_from_dataframe() method that is used for making various adjustments and it is also useful to load the images directly using a single command. So, we convert all the images into 32*32 pixels and define batch size as 64 that is how many images are to be imported and changed simultaneously.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">## If this returns an error, it should be either path is wrong or the parameters that are entered are not valid ones.
</span>
<span class="n">path_train</span> <span class="o">=</span> <span class="s">'./images'</span>

<span class="n">train_df</span> <span class="o">=</span> <span class="n">data_generator</span><span class="p">.</span><span class="n">flow_from_dataframe</span><span class="p">(</span><span class="n">dataframe</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span>
                                              <span class="n">directory</span><span class="o">=</span><span class="n">path_train</span><span class="p">,</span>
                                                    <span class="n">x_col</span><span class="o">=</span><span class="s">'image'</span><span class="p">,</span>
                                                    <span class="n">y_col</span><span class="o">=</span><span class="s">'category'</span><span class="p">,</span>
                                                    <span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">),</span>
                                                    <span class="n">class_mode</span><span class="o">=</span><span class="s">'sparse'</span><span class="p">,</span>
                                                    <span class="n">subset</span><span class="o">=</span><span class="s">'training'</span><span class="p">,</span>
                                                    <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
                                                    <span class="n">seed</span> <span class="o">=</span><span class="mi">1</span>
                                                    <span class="p">)</span>
<span class="n">val_df</span> <span class="o">=</span> <span class="n">data_generator</span><span class="p">.</span><span class="n">flow_from_dataframe</span><span class="p">(</span><span class="n">dataframe</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span>
                                            <span class="n">directory</span><span class="o">=</span><span class="n">path_train</span><span class="p">,</span>
                                            <span class="n">x_col</span><span class="o">=</span><span class="s">'image'</span><span class="p">,</span>
                                                    <span class="n">y_col</span><span class="o">=</span><span class="s">'category'</span><span class="p">,</span>
                                                    <span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">),</span>
                                                    <span class="n">class_mode</span><span class="o">=</span><span class="s">'sparse'</span><span class="p">,</span>
                                                    <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
                                                    <span class="n">subset</span><span class="o">=</span><span class="s">'validation'</span><span class="p">,</span>
                                                    <span class="n">seed</span> <span class="o">=</span><span class="mi">1</span>
                                                    <span class="p">)</span>
<span class="n">test_df</span> <span class="o">=</span> <span class="n">data_generator</span><span class="p">.</span><span class="n">flow_from_dataframe</span><span class="p">(</span><span class="n">dataframe</span><span class="o">=</span><span class="n">test_data</span><span class="p">,</span>
                                            <span class="n">directory</span><span class="o">=</span><span class="n">path_train</span><span class="p">,</span>
                                            <span class="n">x_col</span><span class="o">=</span><span class="s">'image'</span><span class="p">,</span>
                                                    <span class="n">y_col</span><span class="o">=</span><span class="s">'category'</span><span class="p">,</span>
                                                    <span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">),</span>
                                                    <span class="n">class_mode</span><span class="o">=</span><span class="s">'sparse'</span><span class="p">,</span>
                                                    <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
                                                    <span class="n">seed</span> <span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Found 4001 validated image filenames belonging to 5 classes.
Found 1000 validated image filenames belonging to 5 classes.
Found 1251 validated image filenames belonging to 5 classes.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">categories</span> <span class="o">=</span> <span class="p">[</span><span class="s">'Cargo'</span><span class="p">,</span><span class="s">'Military'</span><span class="p">,</span> <span class="s">'Carrier'</span><span class="p">,</span> <span class="s">'Cruise'</span><span class="p">,</span> <span class="s">'Tankers'</span><span class="p">]</span>
</code></pre></div></div>

<h3 id="defining-four-functions">Defining four functions</h3>
<ol>
  <li>Model a network</li>
  <li>Training the model with the given parameters,</li>
  <li>Plotting the training process and</li>
  <li>Printing testing results</li>
</ol>

<p>This part is important since we reuse these functions many times in the project for experimenting with different hyperparameters etc and the functions come in handy as we just need to replace only some parameters</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">model_cnn</span><span class="p">(</span><span class="n">activation_func</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss_func</span><span class="p">):</span>
    <span class="s">"""This function takes the activation function, optimizer and the loss function for the CNN, compiles it and returns the model"""</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="p">.</span><span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation_func</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
    <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
    <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation_func</span><span class="p">))</span>
    <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
    <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation_func</span><span class="p">))</span>
    <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Flatten</span><span class="p">())</span>
    <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation_func</span><span class="p">))</span>
    <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
    <span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">loss_func</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">model</span>

</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">epochs</span><span class="p">):</span>
    <span class="s">"""This function trains the given model with specified number of epochs. It returns the training results"""</span>
    <span class="n">train_steps</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">.</span><span class="n">n</span><span class="o">//</span><span class="n">train_df</span><span class="p">.</span><span class="n">batch_size</span>
    <span class="n">val_steps</span> <span class="o">=</span> <span class="n">val_df</span><span class="p">.</span><span class="n">n</span><span class="o">//</span><span class="n">val_df</span><span class="p">.</span><span class="n">batch_size</span>
    <span class="n">train_results</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_df</span><span class="p">,</span>
                              <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">train_steps</span><span class="p">,</span>
                              <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
                              <span class="n">validation_data</span><span class="o">=</span><span class="n">val_df</span><span class="p">,</span>
                              <span class="n">validation_steps</span><span class="o">=</span><span class="n">val_steps</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">train_results</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">plot_train_results</span><span class="p">(</span><span class="n">train_results</span><span class="p">):</span>
    <span class="s">"""This functin plots and displays the training results (Training Accuracy, Validation Accuracy) over the number of epochs"""</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">train_results</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">]</span>
    <span class="n">val_acc</span> <span class="o">=</span> <span class="n">train_results</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_accuracy'</span><span class="p">]</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="n">train_results</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'loss'</span><span class="p">]</span>
    <span class="n">val_loss</span> <span class="o">=</span> <span class="n">train_results</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_loss'</span><span class="p">]</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Training Accuracy'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">val_acc</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Validation Accuracy'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'best'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Accuracy'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">([</span><span class="nb">min</span><span class="p">(</span><span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">()),</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Training and Validation Accuracy'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Training Loss'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">val_loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Validation Loss'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'best'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Loss'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="nb">max</span><span class="p">(</span><span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">())])</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Training and Validation Loss'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Epoch'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">test_results</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">testing_data</span><span class="p">):</span>
    <span class="s">"""This function return the testing accuracy and loss of the specified model"""</span>
    <span class="n">test_loss</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_df</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'====================='</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Test loss: {:.2f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">test_loss</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Test accuracy: {:.2f}%'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">test_acc</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'====================='</span><span class="p">)</span>
    <span class="k">return</span>
</code></pre></div></div>

<h3 id="the-cnn-model-1">The CNN Model 1:</h3>
<p>Parameters:</p>
<ul>
  <li>Activation function = ReLU.</li>
  <li>Loss function = SparseCategoricalCrossentropy()</li>
  <li>Optimizer = ADAM</li>
</ul>

<p>More information about ReLU can be found <a href="https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/##:~:text=The%20rectified%20linear%20activation%20function%20or%20ReLU%20for,easier%20to%20train%20and%20often%20achieves%20better%20performance.">here</a>. About Sparse Categorical Cross Entropy, it is <a href="https://leakyrelu.com/2020/01/01/difference-between-categorical-and-sparse-categorical-cross-entropy-loss-function/">here</a> and ‘ADAM’ optimizer it is <a href="https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/##:~:text=Adam%20is%20an%20optimization%20algorithm%20that%20can%20be,name%20Adam%20is%20derived%20from%20adaptive%20moment%20estimation.">here</a></p>

<p>The convolution neural network is formed by 3 conv2d layers, 2 MaxPooling and 1 Flatten and 1 Dense layers.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model_1</span> <span class="o">=</span> <span class="n">model_cnn</span><span class="p">(</span><span class="s">'relu'</span><span class="p">,</span><span class="s">'adam'</span><span class="p">,</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
<span class="n">model_1</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param ##
=================================================================
conv2d (Conv2D)              (None, 30, 30, 32)        896
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 4, 4, 64)          36928
_________________________________________________________________
flatten (Flatten)            (None, 1024)              0
_________________________________________________________________
dense (Dense)                (None, 64)                65600
_________________________________________________________________
dense_1 (Dense)              (None, 10)                650
=================================================================
Total params: 122,570
Trainable params: 122,570
Non-trainable params: 0
_________________________________________________________________
</code></pre></div></div>

<p>The model is trained for 15 epochs and the maximum validation accuracy achieved is 69.17%</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">epochs</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">train_results</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">model_1</span><span class="p">,</span><span class="n">epochs</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1/15
62/62 [==============================] - 7s 101ms/step - loss: 1.7405 - accuracy: 0.2884 - val_loss: 1.4835 - val_accuracy: 0.3948
Epoch 2/15
62/62 [==============================] - 5s 87ms/step - loss: 1.4448 - accuracy: 0.3828 - val_loss: 1.2789 - val_accuracy: 0.4927
Epoch 3/15
62/62 [==============================] - 6s 90ms/step - loss: 1.2544 - accuracy: 0.4839 - val_loss: 1.1777 - val_accuracy: 0.5552
Epoch 4/15
62/62 [==============================] - 5s 86ms/step - loss: 1.1524 - accuracy: 0.5450 - val_loss: 1.1879 - val_accuracy: 0.5063
Epoch 5/15
62/62 [==============================] - 5s 85ms/step - loss: 1.0981 - accuracy: 0.5534 - val_loss: 1.1587 - val_accuracy: 0.5104
Epoch 6/15
62/62 [==============================] - 5s 83ms/step - loss: 1.0664 - accuracy: 0.5548 - val_loss: 1.0386 - val_accuracy: 0.5833
Epoch 7/15
62/62 [==============================] - 5s 83ms/step - loss: 0.9567 - accuracy: 0.6137 - val_loss: 1.0117 - val_accuracy: 0.5969
Epoch 8/15
62/62 [==============================] - 5s 82ms/step - loss: 0.9011 - accuracy: 0.6335 - val_loss: 0.9296 - val_accuracy: 0.6167
Epoch 9/15
62/62 [==============================] - 5s 82ms/step - loss: 0.8626 - accuracy: 0.6472 - val_loss: 0.9149 - val_accuracy: 0.6354
Epoch 10/15
62/62 [==============================] - 5s 85ms/step - loss: 0.8750 - accuracy: 0.6405 - val_loss: 0.9326 - val_accuracy: 0.6021
Epoch 11/15
62/62 [==============================] - 5s 85ms/step - loss: 0.8127 - accuracy: 0.6791 - val_loss: 0.8637 - val_accuracy: 0.6479
Epoch 12/15
62/62 [==============================] - 6s 97ms/step - loss: 0.7669 - accuracy: 0.7055 - val_loss: 0.8955 - val_accuracy: 0.6396
Epoch 13/15
62/62 [==============================] - 6s 93ms/step - loss: 0.7713 - accuracy: 0.6892 - val_loss: 0.9238 - val_accuracy: 0.6292
Epoch 14/15
62/62 [==============================] - 6s 94ms/step - loss: 0.7178 - accuracy: 0.7122 - val_loss: 0.8645 - val_accuracy: 0.6562
Epoch 15/15
62/62 [==============================] - 5s 87ms/step - loss: 0.7035 - accuracy: 0.7180 - val_loss: 0.8518 - val_accuracy: 0.6625
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot_train_results</span><span class="p">(</span><span class="n">train_results</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="assets/images/output_27_1.png" alt="png" /></p>

<p>The testing accuracy is near to validation accuracy and it is 68.43%</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">##Testing results:
</span><span class="n">test_results</span><span class="p">(</span><span class="n">model_1</span><span class="p">,</span> <span class="n">test_df</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>20/20 - 1s - loss: 0.9300 - accuracy: 0.6259
=====================
Test loss: 0.93
Test accuracy: 62.59%
=====================
</code></pre></div></div>

<h2 id="part-b-changing-the-activation-function">Part B: Changing the activation function</h2>
<p>Parameters:</p>
<ul>
  <li>Activation function = TanH.</li>
  <li>Loss function = SparseCategoricalCrossentropy()</li>
  <li>Optimizer = ADAM</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model_2</span> <span class="o">=</span> <span class="n">model_cnn</span><span class="p">(</span><span class="s">'tanh'</span><span class="p">,</span><span class="s">'adam'</span><span class="p">,</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
<span class="n">model_2</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param ##
=================================================================
conv2d_3 (Conv2D)            (None, 30, 30, 32)        896
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 15, 15, 32)        0
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 13, 13, 64)        18496
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 4, 4, 64)          36928
_________________________________________________________________
flatten_1 (Flatten)          (None, 1024)              0
_________________________________________________________________
dense_2 (Dense)              (None, 64)                65600
_________________________________________________________________
dense_3 (Dense)              (None, 10)                650
=================================================================
Total params: 122,570
Trainable params: 122,570
Non-trainable params: 0
_________________________________________________________________
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">epochs</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">train_results</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">model_2</span><span class="p">,</span><span class="n">epochs</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1/15
62/62 [==============================] - 6s 88ms/step - loss: 1.6190 - accuracy: 0.3157 - val_loss: 1.3705 - val_accuracy: 0.4417
Epoch 2/15
62/62 [==============================] - 5s 81ms/step - loss: 1.2825 - accuracy: 0.4700 - val_loss: 1.2340 - val_accuracy: 0.5135
Epoch 3/15
62/62 [==============================] - 5s 81ms/step - loss: 1.1535 - accuracy: 0.5404 - val_loss: 1.1345 - val_accuracy: 0.5490
Epoch 4/15
62/62 [==============================] - 5s 77ms/step - loss: 1.0118 - accuracy: 0.5965 - val_loss: 1.0057 - val_accuracy: 0.6135
Epoch 5/15
62/62 [==============================] - 5s 78ms/step - loss: 0.9135 - accuracy: 0.6439 - val_loss: 0.9652 - val_accuracy: 0.6229
Epoch 6/15
62/62 [==============================] - 5s 81ms/step - loss: 0.8580 - accuracy: 0.6603 - val_loss: 0.8991 - val_accuracy: 0.6375
Epoch 7/15
62/62 [==============================] - 6s 93ms/step - loss: 0.8011 - accuracy: 0.6837 - val_loss: 0.9029 - val_accuracy: 0.6458
Epoch 8/15
62/62 [==============================] - 6s 103ms/step - loss: 0.7417 - accuracy: 0.7139 - val_loss: 0.8599 - val_accuracy: 0.6740
Epoch 9/15
62/62 [==============================] - 7s 117ms/step - loss: 0.6679 - accuracy: 0.7578 - val_loss: 0.8518 - val_accuracy: 0.6635
Epoch 10/15
62/62 [==============================] - 9s 138ms/step - loss: 0.6285 - accuracy: 0.7644 - val_loss: 0.8348 - val_accuracy: 0.6844
Epoch 11/15
62/62 [==============================] - 9s 149ms/step - loss: 0.5681 - accuracy: 0.7927 - val_loss: 0.8422 - val_accuracy: 0.6729
Epoch 12/15
62/62 [==============================] - 10s 163ms/step - loss: 0.5281 - accuracy: 0.8149 - val_loss: 0.8398 - val_accuracy: 0.6677
Epoch 13/15
62/62 [==============================] - 9s 149ms/step - loss: 0.4769 - accuracy: 0.8302 - val_loss: 0.8490 - val_accuracy: 0.6719
Epoch 14/15
62/62 [==============================] - 8s 123ms/step - loss: 0.4327 - accuracy: 0.8532 - val_loss: 0.8516 - val_accuracy: 0.6646
Epoch 15/15
62/62 [==============================] - 7s 108ms/step - loss: 0.3815 - accuracy: 0.8797 - val_loss: 0.8594 - val_accuracy: 0.6927
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot_train_results</span><span class="p">(</span><span class="n">train_results</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="assets/images/output_33_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">##Testing Results
</span>
<span class="n">test_results</span><span class="p">(</span><span class="n">model_2</span><span class="p">,</span> <span class="n">test_df</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>20/20 - 2s - loss: 0.9710 - accuracy: 0.6395
=====================
Test loss: 0.97
Test accuracy: 63.95%
=====================
</code></pre></div></div>

<p>The tanh activation function gave a similar accuracy than relu function with around 63.14% and the learning speed is similar to relu function.</p>

<h3 id="another-activation-function">Another Activation function</h3>
<p>Parameters:</p>
<ul>
  <li>Activation function = softsign.</li>
  <li>Loss function = SparseCategoricalCrossentropy()</li>
  <li>Optimizer = ADAM</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model_3</span> <span class="o">=</span> <span class="n">model_cnn</span><span class="p">(</span><span class="s">'softsign'</span><span class="p">,</span> <span class="s">'adam'</span><span class="p">,</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
<span class="n">model_3</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param ##
=================================================================
conv2d_6 (Conv2D)            (None, 30, 30, 32)        896
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 15, 15, 32)        0
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 13, 13, 64)        18496
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 6, 6, 64)          0
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 4, 4, 64)          36928
_________________________________________________________________
flatten_2 (Flatten)          (None, 1024)              0
_________________________________________________________________
dense_4 (Dense)              (None, 64)                65600
_________________________________________________________________
dense_5 (Dense)              (None, 10)                650
=================================================================
Total params: 122,570
Trainable params: 122,570
Non-trainable params: 0
_________________________________________________________________
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">epochs</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">train_results</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">model_3</span><span class="p">,</span><span class="n">epochs</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1/15
62/62 [==============================] - 7s 102ms/step - loss: 1.6785 - accuracy: 0.3293 - val_loss: 1.5235 - val_accuracy: 0.3458
Epoch 2/15
62/62 [==============================] - 6s 92ms/step - loss: 1.5123 - accuracy: 0.3600 - val_loss: 1.3355 - val_accuracy: 0.4625
Epoch 3/15
62/62 [==============================] - 5s 87ms/step - loss: 1.2976 - accuracy: 0.4683 - val_loss: 1.1985 - val_accuracy: 0.5156
Epoch 4/15
62/62 [==============================] - 5s 81ms/step - loss: 1.1699 - accuracy: 0.5310 - val_loss: 1.0910 - val_accuracy: 0.5760
Epoch 5/15
62/62 [==============================] - 5s 74ms/step - loss: 1.0522 - accuracy: 0.5699 - val_loss: 1.0644 - val_accuracy: 0.5823
Epoch 6/15
62/62 [==============================] - 5s 73ms/step - loss: 1.0090 - accuracy: 0.5891 - val_loss: 1.0147 - val_accuracy: 0.6052
Epoch 7/15
62/62 [==============================] - 5s 73ms/step - loss: 0.9222 - accuracy: 0.6321 - val_loss: 0.9392 - val_accuracy: 0.6198
Epoch 8/15
62/62 [==============================] - 5s 77ms/step - loss: 0.8879 - accuracy: 0.6440 - val_loss: 0.9838 - val_accuracy: 0.6250
Epoch 9/15
62/62 [==============================] - 5s 79ms/step - loss: 0.8324 - accuracy: 0.6767 - val_loss: 0.8939 - val_accuracy: 0.6448
Epoch 10/15
62/62 [==============================] - 5s 78ms/step - loss: 0.7615 - accuracy: 0.7074 - val_loss: 0.8519 - val_accuracy: 0.6573
Epoch 11/15
62/62 [==============================] - 5s 79ms/step - loss: 0.7358 - accuracy: 0.7133 - val_loss: 0.8610 - val_accuracy: 0.6573
Epoch 12/15
62/62 [==============================] - 5s 86ms/step - loss: 0.6889 - accuracy: 0.7286 - val_loss: 0.8551 - val_accuracy: 0.6604
Epoch 13/15
62/62 [==============================] - 6s 95ms/step - loss: 0.6611 - accuracy: 0.7434 - val_loss: 0.8206 - val_accuracy: 0.6844
Epoch 14/15
62/62 [==============================] - 7s 111ms/step - loss: 0.6102 - accuracy: 0.7576 - val_loss: 0.8400 - val_accuracy: 0.6573
Epoch 15/15
62/62 [==============================] - 8s 125ms/step - loss: 0.5864 - accuracy: 0.7683 - val_loss: 0.8124 - val_accuracy: 0.6792
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot_train_results</span><span class="p">(</span><span class="n">train_results</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="assets/images/output_39_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_results</span><span class="p">(</span><span class="n">model_3</span><span class="p">,</span> <span class="n">test_df</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>20/20 - 2s - loss: 0.8889 - accuracy: 0.6395
=====================
Test loss: 0.89
Test accuracy: 63.95%
=====================
</code></pre></div></div>

<p>The softsign activation function gave very less accuracy than tanh function with around 24%  and the learning speed is similar to relu function.</p>

<h2 id="part-c-changing-loss-function">Part C: Changing Loss function</h2>
<p>Parameters:</p>
<ul>
  <li>Activation function = ReLU.</li>
  <li>Loss function = categorical_hinge</li>
  <li>Optimizer = ADAM</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">## model 4:
</span><span class="n">model_4</span> <span class="o">=</span> <span class="n">model_cnn</span><span class="p">(</span><span class="s">'relu'</span><span class="p">,</span> <span class="s">'adam'</span><span class="p">,</span> <span class="s">'categorical_hinge'</span><span class="p">)</span>
<span class="n">model_4</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Model: "sequential_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param ##
=================================================================
conv2d_9 (Conv2D)            (None, 30, 30, 32)        896
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 15, 15, 32)        0
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 13, 13, 64)        18496
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 6, 6, 64)          0
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 4, 4, 64)          36928
_________________________________________________________________
flatten_3 (Flatten)          (None, 1024)              0
_________________________________________________________________
dense_6 (Dense)              (None, 64)                65600
_________________________________________________________________
dense_7 (Dense)              (None, 10)                650
=================================================================
Total params: 122,570
Trainable params: 122,570
Non-trainable params: 0
_________________________________________________________________
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">epochs</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">train_results</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">model_4</span><span class="p">,</span><span class="n">epochs</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1/15
62/62 [==============================] - 10s 156ms/step - loss: 0.4755 - accuracy: 0.0979 - val_loss: 0.3857 - val_accuracy: 0.0990
Epoch 2/15
62/62 [==============================] - 9s 140ms/step - loss: 0.3808 - accuracy: 0.1145 - val_loss: 0.3913 - val_accuracy: 0.1187
Epoch 3/15
62/62 [==============================] - 8s 124ms/step - loss: 0.3726 - accuracy: 0.1221 - val_loss: 0.3759 - val_accuracy: 0.0667
Epoch 4/15
62/62 [==============================] - 7s 109ms/step - loss: 0.3724 - accuracy: 0.0898 - val_loss: 0.3864 - val_accuracy: 0.0500
Epoch 5/15
62/62 [==============================] - 6s 97ms/step - loss: 0.3620 - accuracy: 0.0935 - val_loss: 0.3781 - val_accuracy: 0.0458
Epoch 6/15
62/62 [==============================] - 6s 92ms/step - loss: 0.3748 - accuracy: 0.0798 - val_loss: 0.3824 - val_accuracy: 0.0490
Epoch 7/15
62/62 [==============================] - 5s 87ms/step - loss: 0.3758 - accuracy: 0.0736 - val_loss: 0.3723 - val_accuracy: 0.1333
Epoch 8/15
62/62 [==============================] - 5s 79ms/step - loss: 0.3769 - accuracy: 0.0979 - val_loss: 0.3734 - val_accuracy: 0.0802
Epoch 9/15
62/62 [==============================] - 5s 74ms/step - loss: 0.3678 - accuracy: 0.0958 - val_loss: 0.3753 - val_accuracy: 0.0979
Epoch 10/15
62/62 [==============================] - 4s 71ms/step - loss: 0.3552 - accuracy: 0.0910 - val_loss: 0.3778 - val_accuracy: 0.0875
Epoch 11/15
62/62 [==============================] - 4s 71ms/step - loss: 0.3682 - accuracy: 0.0931 - val_loss: 0.3708 - val_accuracy: 0.0479
Epoch 12/15
62/62 [==============================] - 4s 71ms/step - loss: 0.3668 - accuracy: 0.1046 - val_loss: 0.3757 - val_accuracy: 0.1125
Epoch 13/15
62/62 [==============================] - 5s 74ms/step - loss: 0.3589 - accuracy: 0.1008 - val_loss: 0.3811 - val_accuracy: 0.1375
Epoch 14/15
62/62 [==============================] - 4s 72ms/step - loss: 0.3728 - accuracy: 0.1107 - val_loss: 0.3673 - val_accuracy: 0.1333
Epoch 15/15
62/62 [==============================] - 5s 74ms/step - loss: 0.3717 - accuracy: 0.1081 - val_loss: 0.3709 - val_accuracy: 0.0417
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot_train_results</span><span class="p">(</span><span class="n">train_results</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="assets/images/output_45_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_results</span><span class="p">(</span><span class="n">model_4</span><span class="p">,</span> <span class="n">test_df</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>20/20 - 1s - loss: 0.3625 - accuracy: 0.0584
=====================
Test loss: 0.36
Test accuracy: 5.84%
=====================
</code></pre></div></div>

<p>Parameters:</p>
<ul>
  <li>Activation function = ReLU.</li>
  <li>Loss function = mean_squared_error</li>
  <li>Optimizer = ADAM</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model_5</span> <span class="o">=</span> <span class="n">model_cnn</span><span class="p">(</span><span class="s">'relu'</span><span class="p">,</span><span class="s">'adam'</span><span class="p">,</span><span class="s">'mean_squared_error'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">epochs</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">train_results</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">model_5</span><span class="p">,</span><span class="n">epochs</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1/15
62/62 [==============================] - 5s 82ms/step - loss: 3.0893 - accuracy: 0.0908 - val_loss: 2.4407 - val_accuracy: 0.0896
Epoch 2/15
62/62 [==============================] - 5s 80ms/step - loss: 2.3597 - accuracy: 0.0979 - val_loss: 2.3992 - val_accuracy: 0.1729
Epoch 3/15
62/62 [==============================] - 5s 81ms/step - loss: 2.2730 - accuracy: 0.1072 - val_loss: 2.2027 - val_accuracy: 0.1521
Epoch 4/15
62/62 [==============================] - 5s 80ms/step - loss: 2.1915 - accuracy: 0.1218 - val_loss: 2.1337 - val_accuracy: 0.2229
Epoch 5/15
62/62 [==============================] - 5s 78ms/step - loss: 2.1258 - accuracy: 0.1222 - val_loss: 2.2753 - val_accuracy: 0.1688
Epoch 6/15
62/62 [==============================] - 5s 78ms/step - loss: 2.0760 - accuracy: 0.1251 - val_loss: 2.0333 - val_accuracy: 0.1021
Epoch 7/15
62/62 [==============================] - 5s 77ms/step - loss: 1.9729 - accuracy: 0.1133 - val_loss: 1.9962 - val_accuracy: 0.1021
Epoch 8/15
62/62 [==============================] - 5s 78ms/step - loss: 1.8959 - accuracy: 0.0951 - val_loss: 1.9665 - val_accuracy: 0.0729
Epoch 9/15
62/62 [==============================] - 5s 79ms/step - loss: 1.8864 - accuracy: 0.0939 - val_loss: 1.9506 - val_accuracy: 0.0875
Epoch 10/15
62/62 [==============================] - 5s 81ms/step - loss: 1.7955 - accuracy: 0.1144 - val_loss: 2.0896 - val_accuracy: 0.1260
Epoch 11/15
62/62 [==============================] - 5s 81ms/step - loss: 1.8928 - accuracy: 0.1304 - val_loss: 1.9422 - val_accuracy: 0.0542
Epoch 12/15
62/62 [==============================] - 5s 81ms/step - loss: 1.6765 - accuracy: 0.0790 - val_loss: 2.0252 - val_accuracy: 0.1000
Epoch 13/15
62/62 [==============================] - 5s 82ms/step - loss: 1.6695 - accuracy: 0.1087 - val_loss: 1.9084 - val_accuracy: 0.0885
Epoch 14/15
62/62 [==============================] - 5s 85ms/step - loss: 1.5910 - accuracy: 0.0929 - val_loss: 1.9530 - val_accuracy: 0.0854
Epoch 15/15
62/62 [==============================] - 5s 84ms/step - loss: 1.3919 - accuracy: 0.0761 - val_loss: 1.9436 - val_accuracy: 0.0958
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot_train_results</span><span class="p">(</span><span class="n">train_results</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="assets/images/output_50_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_results</span><span class="p">(</span><span class="n">model_5</span><span class="p">,</span> <span class="n">test_df</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>20/20 - 1s - loss: 2.1826 - accuracy: 0.1143
=====================
Test loss: 2.18
Test accuracy: 11.43%
=====================
</code></pre></div></div>

<h2 id="changing-epochs">Changing Epochs</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model_1</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param ##
=================================================================
conv2d (Conv2D)              (None, 30, 30, 32)        896
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 4, 4, 64)          36928
_________________________________________________________________
flatten (Flatten)            (None, 1024)              0
_________________________________________________________________
dense (Dense)                (None, 64)                65600
_________________________________________________________________
dense_1 (Dense)              (None, 10)                650
=================================================================
Total params: 122,570
Trainable params: 122,570
Non-trainable params: 0
_________________________________________________________________
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">train_results</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">model_1</span><span class="p">,</span><span class="n">epochs</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1/10
62/62 [==============================] - 5s 86ms/step - loss: 0.6592 - accuracy: 0.7358 - val_loss: 0.8438 - val_accuracy: 0.6698
Epoch 2/10
62/62 [==============================] - 5s 84ms/step - loss: 0.6359 - accuracy: 0.7536 - val_loss: 0.8549 - val_accuracy: 0.6573
Epoch 3/10
62/62 [==============================] - 5s 87ms/step - loss: 0.5907 - accuracy: 0.7750 - val_loss: 0.8946 - val_accuracy: 0.6438
Epoch 4/10
62/62 [==============================] - 5s 85ms/step - loss: 0.5770 - accuracy: 0.7790 - val_loss: 0.8956 - val_accuracy: 0.6354
Epoch 5/10
62/62 [==============================] - 5s 85ms/step - loss: 0.5366 - accuracy: 0.7945 - val_loss: 0.8635 - val_accuracy: 0.6792
Epoch 6/10
62/62 [==============================] - 5s 87ms/step - loss: 0.4973 - accuracy: 0.8153 - val_loss: 0.8714 - val_accuracy: 0.6677
Epoch 7/10
62/62 [==============================] - 5s 83ms/step - loss: 0.4930 - accuracy: 0.8153 - val_loss: 0.8512 - val_accuracy: 0.6802
Epoch 8/10
62/62 [==============================] - 5s 84ms/step - loss: 0.4507 - accuracy: 0.8252 - val_loss: 0.9301 - val_accuracy: 0.6448
Epoch 9/10
62/62 [==============================] - 5s 84ms/step - loss: 0.4413 - accuracy: 0.8288 - val_loss: 0.9358 - val_accuracy: 0.6479
Epoch 10/10
62/62 [==============================] - 5s 84ms/step - loss: 0.4063 - accuracy: 0.8539 - val_loss: 0.8459 - val_accuracy: 0.6917
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot_train_results</span><span class="p">(</span><span class="n">train_results</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="assets/images/output_55_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_results</span><span class="p">(</span><span class="n">model_1</span><span class="p">,</span> <span class="n">test_df</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>20/20 - 1s - loss: 0.8958 - accuracy: 0.6579
=====================
Test loss: 0.90
Test accuracy: 65.79%
=====================
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">epochs</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">train_results</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">model_1</span><span class="p">,</span> <span class="n">epochs</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1/5
62/62 [==============================] - 5s 82ms/step - loss: 0.3913 - accuracy: 0.8631 - val_loss: 0.8762 - val_accuracy: 0.6771
Epoch 2/5
62/62 [==============================] - 5s 82ms/step - loss: 0.3281 - accuracy: 0.8824 - val_loss: 0.9440 - val_accuracy: 0.6927
Epoch 3/5
62/62 [==============================] - 5s 81ms/step - loss: 0.3325 - accuracy: 0.8806 - val_loss: 0.9987 - val_accuracy: 0.6719
Epoch 4/5
62/62 [==============================] - 5s 82ms/step - loss: 0.2898 - accuracy: 0.9017 - val_loss: 0.9753 - val_accuracy: 0.6854
Epoch 5/5
62/62 [==============================] - 5s 83ms/step - loss: 0.2564 - accuracy: 0.9139 - val_loss: 0.9933 - val_accuracy: 0.6781
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot_train_results</span><span class="p">(</span><span class="n">train_results</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="assets/images/output_58_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_results</span><span class="p">(</span><span class="n">model_1</span><span class="p">,</span> <span class="n">test_df</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>20/20 - 1s - loss: 1.0752 - accuracy: 0.6619
=====================
Test loss: 1.08
Test accuracy: 66.19%
=====================
</code></pre></div></div>

<h2 id="changing-gradient-estimation">Changing Gradient Estimation</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model_6</span> <span class="o">=</span> <span class="n">model_cnn</span><span class="p">(</span><span class="n">activation_func</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s">'Adagrad'</span><span class="p">,</span>
                    <span class="n">loss_func</span><span class="o">=</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>
<span class="n">model_6</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Model: "sequential_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param ##
=================================================================
conv2d_15 (Conv2D)           (None, 30, 30, 32)        896
_________________________________________________________________
max_pooling2d_10 (MaxPooling (None, 15, 15, 32)        0
_________________________________________________________________
conv2d_16 (Conv2D)           (None, 13, 13, 64)        18496
_________________________________________________________________
max_pooling2d_11 (MaxPooling (None, 6, 6, 64)          0
_________________________________________________________________
conv2d_17 (Conv2D)           (None, 4, 4, 64)          36928
_________________________________________________________________
flatten_5 (Flatten)          (None, 1024)              0
_________________________________________________________________
dense_10 (Dense)             (None, 64)                65600
_________________________________________________________________
dense_11 (Dense)             (None, 10)                650
=================================================================
Total params: 122,570
Trainable params: 122,570
Non-trainable params: 0
_________________________________________________________________
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_results</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model_6</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1/10
62/62 [==============================] - 5s 81ms/step - loss: 4.3974 - accuracy: 0.2103 - val_loss: 1.5439 - val_accuracy: 0.3490
Epoch 2/10
62/62 [==============================] - 5s 82ms/step - loss: 1.5245 - accuracy: 0.3349 - val_loss: 1.5005 - val_accuracy: 0.3458
Epoch 3/10
62/62 [==============================] - 5s 83ms/step - loss: 1.4969 - accuracy: 0.3373 - val_loss: 1.4884 - val_accuracy: 0.3521
Epoch 4/10
62/62 [==============================] - 5s 83ms/step - loss: 1.4938 - accuracy: 0.3449 - val_loss: 1.4700 - val_accuracy: 0.3479
Epoch 5/10
62/62 [==============================] - 5s 85ms/step - loss: 1.4737 - accuracy: 0.3510 - val_loss: 1.5052 - val_accuracy: 0.3479
Epoch 6/10
62/62 [==============================] - 6s 89ms/step - loss: 1.4660 - accuracy: 0.3747 - val_loss: 1.6042 - val_accuracy: 0.2802
Epoch 7/10
62/62 [==============================] - 6s 97ms/step - loss: 1.5507 - accuracy: 0.3056 - val_loss: 1.4875 - val_accuracy: 0.3500
Epoch 8/10
62/62 [==============================] - 7s 108ms/step - loss: 1.4770 - accuracy: 0.3446 - val_loss: 1.4322 - val_accuracy: 0.3688
Epoch 9/10
62/62 [==============================] - 7s 115ms/step - loss: 1.4669 - accuracy: 0.3790 - val_loss: 1.7072 - val_accuracy: 0.4146
Epoch 10/10
62/62 [==============================] - 6s 100ms/step - loss: 1.4681 - accuracy: 0.4024 - val_loss: 1.4456 - val_accuracy: 0.3844
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot_train_results</span><span class="p">(</span><span class="n">train_results</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="assets/images/output_63_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_results</span><span class="p">(</span><span class="n">model_6</span><span class="p">,</span> <span class="n">test_df</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>20/20 - 2s - loss: 1.4528 - accuracy: 0.3733
=====================
Test loss: 1.45
Test accuracy: 37.33%
=====================
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">## Model 7
</span><span class="n">model_7</span> <span class="o">=</span> <span class="n">model_cnn</span><span class="p">(</span><span class="s">'relu'</span><span class="p">,</span> <span class="s">'Adamax'</span><span class="p">,</span> <span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>
<span class="n">model_7</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Model: "sequential_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param ##
=================================================================
conv2d_18 (Conv2D)           (None, 30, 30, 32)        896
_________________________________________________________________
max_pooling2d_12 (MaxPooling (None, 15, 15, 32)        0
_________________________________________________________________
conv2d_19 (Conv2D)           (None, 13, 13, 64)        18496
_________________________________________________________________
max_pooling2d_13 (MaxPooling (None, 6, 6, 64)          0
_________________________________________________________________
conv2d_20 (Conv2D)           (None, 4, 4, 64)          36928
_________________________________________________________________
flatten_6 (Flatten)          (None, 1024)              0
_________________________________________________________________
dense_12 (Dense)             (None, 64)                65600
_________________________________________________________________
dense_13 (Dense)             (None, 10)                650
=================================================================
Total params: 122,570
Trainable params: 122,570
Non-trainable params: 0
_________________________________________________________________
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_results</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">model_7</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1/10
62/62 [==============================] - 6s 90ms/step - loss: 5.7976 - accuracy: 0.2408 - val_loss: 2.3026 - val_accuracy: 0.1052
Epoch 2/10
62/62 [==============================] - 5s 81ms/step - loss: 2.3026 - accuracy: 0.1146 - val_loss: 2.3026 - val_accuracy: 0.1094
Epoch 3/10
62/62 [==============================] - 5s 79ms/step - loss: 2.3026 - accuracy: 0.1232 - val_loss: 2.3026 - val_accuracy: 0.1063
Epoch 4/10
62/62 [==============================] - 5s 81ms/step - loss: 2.3026 - accuracy: 0.1336 - val_loss: 2.3026 - val_accuracy: 0.1083
Epoch 5/10
62/62 [==============================] - 5s 79ms/step - loss: 2.3026 - accuracy: 0.1317 - val_loss: 2.3026 - val_accuracy: 0.1083
Epoch 6/10
62/62 [==============================] - 5s 77ms/step - loss: 2.3026 - accuracy: 0.1344 - val_loss: 2.3026 - val_accuracy: 0.1073
Epoch 7/10
62/62 [==============================] - 5s 76ms/step - loss: 2.3026 - accuracy: 0.1199 - val_loss: 2.3026 - val_accuracy: 0.1073
Epoch 8/10
62/62 [==============================] - 5s 78ms/step - loss: 2.3026 - accuracy: 0.1261 - val_loss: 2.3026 - val_accuracy: 0.1073
Epoch 9/10
62/62 [==============================] - 5s 78ms/step - loss: 2.3026 - accuracy: 0.1302 - val_loss: 2.3026 - val_accuracy: 0.1083
Epoch 10/10
62/62 [==============================] - 5s 78ms/step - loss: 2.3026 - accuracy: 0.1341 - val_loss: 2.3026 - val_accuracy: 0.1094
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot_train_results</span><span class="p">(</span><span class="n">train_results</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="assets/images/output_67_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_results</span><span class="p">(</span><span class="n">model_7</span><span class="p">,</span><span class="n">test_df</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>20/20 - 1s - loss: 2.3026 - accuracy: 0.1271
=====================
Test loss: 2.30
Test accuracy: 12.71%
=====================
</code></pre></div></div>

<h2 id="changing-network-architecture">Changing Network Architecture</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">##Removing a convolution layer in the model
</span><span class="n">model_8</span> <span class="o">=</span> <span class="n">models</span><span class="p">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model_8</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
<span class="n">model_8</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="c1">##model.add(layers.Conv2D(64, (3, 3), activation='relu'))
##model.add(layers.MaxPooling2D((2, 2)))
</span><span class="n">model_8</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
<span class="n">model_8</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model_8</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
<span class="n">model_8</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="n">model_8</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model_8</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Model: "sequential_7"
_________________________________________________________________
Layer (type)                 Output Shape              Param ##
=================================================================
conv2d_21 (Conv2D)           (None, 30, 30, 32)        896
_________________________________________________________________
max_pooling2d_14 (MaxPooling (None, 15, 15, 32)        0
_________________________________________________________________
conv2d_22 (Conv2D)           (None, 13, 13, 64)        18496
_________________________________________________________________
flatten_7 (Flatten)          (None, 10816)             0
_________________________________________________________________
dense_14 (Dense)             (None, 64)                692288
_________________________________________________________________
dense_15 (Dense)             (None, 10)                650
=================================================================
Total params: 712,330
Trainable params: 712,330
Non-trainable params: 0
_________________________________________________________________
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_results</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">model_8</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1/10
62/62 [==============================] - 6s 86ms/step - loss: 6.6433 - accuracy: 0.2508 - val_loss: 6.1531 - val_accuracy: 0.1937
Epoch 2/10
62/62 [==============================] - 5s 84ms/step - loss: 6.4086 - accuracy: 0.1819 - val_loss: 6.1475 - val_accuracy: 0.1937
Epoch 3/10
62/62 [==============================] - 5s 84ms/step - loss: 6.3801 - accuracy: 0.1829 - val_loss: 6.1199 - val_accuracy: 0.1958
Epoch 4/10
62/62 [==============================] - 5s 84ms/step - loss: 4.5437 - accuracy: 0.2276 - val_loss: 2.3026 - val_accuracy: 0.0052
Epoch 5/10
62/62 [==============================] - 5s 83ms/step - loss: 2.3026 - accuracy: 0.0019 - val_loss: 2.3026 - val_accuracy: 0.0010
Epoch 6/10
62/62 [==============================] - 5s 84ms/step - loss: 2.3026 - accuracy: 0.0013 - val_loss: 2.3026 - val_accuracy: 0.0010
Epoch 7/10
62/62 [==============================] - 5s 82ms/step - loss: 2.3026 - accuracy: 0.0020 - val_loss: 2.3026 - val_accuracy: 0.0000e+00
Epoch 8/10
62/62 [==============================] - 5s 81ms/step - loss: 2.3026 - accuracy: 8.3142e-04 - val_loss: 2.3026 - val_accuracy: 0.0010
Epoch 9/10
62/62 [==============================] - 5s 78ms/step - loss: 2.3026 - accuracy: 0.0017 - val_loss: 2.3026 - val_accuracy: 0.0010
Epoch 10/10
62/62 [==============================] - 5s 78ms/step - loss: 2.3026 - accuracy: 0.0017 - val_loss: 2.3026 - val_accuracy: 0.0010
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot_train_results</span><span class="p">(</span><span class="n">train_results</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="assets/images/output_73_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_results</span><span class="p">(</span><span class="n">model_8</span><span class="p">,</span><span class="n">test_df</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>20/20 - 1s - loss: 2.3026 - accuracy: 0.0032
=====================
Test loss: 2.30
Test accuracy: 0.32%
=====================
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">##Removing a convolution layer in the model
</span>
<span class="n">model_9</span> <span class="o">=</span> <span class="n">models</span><span class="p">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model_9</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
<span class="n">model_9</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">model_9</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
<span class="n">model_9</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">model_9</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
<span class="n">model_9</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model_9</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
<span class="n">model_9</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="n">model_9</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
<span class="n">model_9</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Model: "sequential_8"
_________________________________________________________________
Layer (type)                 Output Shape              Param ##
=================================================================
conv2d_23 (Conv2D)           (None, 30, 30, 32)        896
_________________________________________________________________
max_pooling2d_15 (MaxPooling (None, 15, 15, 32)        0
_________________________________________________________________
conv2d_24 (Conv2D)           (None, 13, 13, 32)        9248
_________________________________________________________________
max_pooling2d_16 (MaxPooling (None, 6, 6, 32)          0
_________________________________________________________________
conv2d_25 (Conv2D)           (None, 4, 4, 32)          9248
_________________________________________________________________
flatten_8 (Flatten)          (None, 512)               0
_________________________________________________________________
dense_16 (Dense)             (None, 32)                16416
_________________________________________________________________
dense_17 (Dense)             (None, 10)                330
=================================================================
Total params: 36,138
Trainable params: 36,138
Non-trainable params: 0
_________________________________________________________________
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_results</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">model_9</span><span class="p">,</span><span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1/10
62/62 [==============================] - 5s 79ms/step - loss: 2.1083 - accuracy: 0.3092 - val_loss: 1.4416 - val_accuracy: 0.4156
Epoch 2/10
62/62 [==============================] - 5s 77ms/step - loss: 1.5179 - accuracy: 0.3717 - val_loss: 1.4855 - val_accuracy: 0.3448
Epoch 3/10
62/62 [==============================] - 5s 81ms/step - loss: 1.4759 - accuracy: 0.3600 - val_loss: 1.5437 - val_accuracy: 0.4354
Epoch 4/10
62/62 [==============================] - 5s 82ms/step - loss: 1.4717 - accuracy: 0.3832 - val_loss: 1.3965 - val_accuracy: 0.4240
Epoch 5/10
62/62 [==============================] - 5s 84ms/step - loss: 1.3408 - accuracy: 0.4511 - val_loss: 2.7434 - val_accuracy: 0.3427
Epoch 6/10
62/62 [==============================] - 5s 82ms/step - loss: 1.8956 - accuracy: 0.3414 - val_loss: 1.6397 - val_accuracy: 0.3688
Epoch 7/10
62/62 [==============================] - 5s 82ms/step - loss: 1.4574 - accuracy: 0.4407 - val_loss: 1.3700 - val_accuracy: 0.4865
Epoch 8/10
62/62 [==============================] - 5s 81ms/step - loss: 1.3993 - accuracy: 0.4241 - val_loss: 1.6245 - val_accuracy: 0.3708
Epoch 9/10
62/62 [==============================] - 5s 83ms/step - loss: 1.6330 - accuracy: 0.3442 - val_loss: 1.6094 - val_accuracy: 0.3469
Epoch 10/10
62/62 [==============================] - 5s 83ms/step - loss: 1.6094 - accuracy: 0.3515 - val_loss: 1.6094 - val_accuracy: 0.3438
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot_train_results</span><span class="p">(</span><span class="n">train_results</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="assets/images/output_77_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_results</span><span class="p">(</span><span class="n">model_9</span><span class="p">,</span><span class="n">test_df</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>20/20 - 1s - loss: 1.6094 - accuracy: 0.3341
=====================
Test loss: 1.61
Test accuracy: 33.41%
=====================
</code></pre></div></div>

<h2 id="changing-network-initialization">Changing Network Initialization</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">initializer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">initializers</span><span class="p">.</span><span class="n">RandomUniform</span><span class="p">()</span>

<span class="n">model_9</span> <span class="o">=</span> <span class="n">models</span><span class="p">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model_9</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
<span class="n">model_9</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">))</span>
<span class="n">model_9</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">model_9</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
<span class="n">model_9</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">model_9</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
<span class="n">model_9</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model_9</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
<span class="n">model_9</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">))</span>
<span class="n">model_9</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
                <span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
<span class="n">model_9</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Model: "sequential_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param ##
=================================================================
conv2d_26 (Conv2D)           (None, 30, 30, 32)        896
_________________________________________________________________
dense_18 (Dense)             (None, 30, 30, 32)        1056
_________________________________________________________________
max_pooling2d_17 (MaxPooling (None, 15, 15, 32)        0
_________________________________________________________________
conv2d_27 (Conv2D)           (None, 13, 13, 64)        18496
_________________________________________________________________
max_pooling2d_18 (MaxPooling (None, 6, 6, 64)          0
_________________________________________________________________
conv2d_28 (Conv2D)           (None, 4, 4, 64)          36928
_________________________________________________________________
flatten_9 (Flatten)          (None, 1024)              0
_________________________________________________________________
dense_19 (Dense)             (None, 64)                65600
_________________________________________________________________
dense_20 (Dense)             (None, 10)                650
=================================================================
Total params: 123,626
Trainable params: 123,626
Non-trainable params: 0
_________________________________________________________________
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_results</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">model_9</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1/10
62/62 [==============================] - 6s 90ms/step - loss: 1.7817 - accuracy: 0.2942 - val_loss: 1.5410 - val_accuracy: 0.3375
Epoch 2/10
62/62 [==============================] - 5s 88ms/step - loss: 1.5308 - accuracy: 0.3543 - val_loss: 1.4086 - val_accuracy: 0.3917
Epoch 3/10
62/62 [==============================] - 6s 90ms/step - loss: 1.4156 - accuracy: 0.3950 - val_loss: 1.3456 - val_accuracy: 0.4542
Epoch 4/10
62/62 [==============================] - 6s 91ms/step - loss: 1.2857 - accuracy: 0.4668 - val_loss: 1.1893 - val_accuracy: 0.5250
Epoch 5/10
62/62 [==============================] - 6s 94ms/step - loss: 1.1351 - accuracy: 0.5254 - val_loss: 1.0977 - val_accuracy: 0.5510
Epoch 6/10
62/62 [==============================] - 6s 93ms/step - loss: 1.0728 - accuracy: 0.5571 - val_loss: 0.9817 - val_accuracy: 0.6187
Epoch 7/10
62/62 [==============================] - 5s 88ms/step - loss: 0.9731 - accuracy: 0.5795 - val_loss: 0.9837 - val_accuracy: 0.6052
Epoch 8/10
62/62 [==============================] - 6s 91ms/step - loss: 0.9474 - accuracy: 0.5872 - val_loss: 0.9200 - val_accuracy: 0.6115
Epoch 9/10
62/62 [==============================] - 6s 91ms/step - loss: 0.9183 - accuracy: 0.6103 - val_loss: 0.9249 - val_accuracy: 0.6198
Epoch 10/10
62/62 [==============================] - 6s 91ms/step - loss: 0.9016 - accuracy: 0.6182 - val_loss: 0.8800 - val_accuracy: 0.6354
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot_train_results</span><span class="p">(</span><span class="n">train_results</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="assets/images/output_82_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_results</span><span class="p">(</span><span class="n">model_9</span><span class="p">,</span><span class="n">test_df</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>20/20 - 2s - loss: 0.9627 - accuracy: 0.5915
=====================
Test loss: 0.96
Test accuracy: 59.15%
=====================
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">initializer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">initializers</span><span class="p">.</span><span class="n">glorot_uniform</span><span class="p">()</span>

<span class="n">model_10</span> <span class="o">=</span> <span class="n">models</span><span class="p">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model_10</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
<span class="n">model_10</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">))</span>
<span class="n">model_10</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">model_10</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
<span class="n">model_10</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">model_10</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
<span class="n">model_10</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model_10</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
<span class="n">model_10</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">))</span>
<span class="n">model_10</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
                 <span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span>
                 <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
<span class="n">model_10</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Model: "sequential_10"
_________________________________________________________________
Layer (type)                 Output Shape              Param ##
=================================================================
conv2d_29 (Conv2D)           (None, 30, 30, 32)        896
_________________________________________________________________
dense_21 (Dense)             (None, 30, 30, 32)        1056
_________________________________________________________________
max_pooling2d_19 (MaxPooling (None, 15, 15, 32)        0
_________________________________________________________________
conv2d_30 (Conv2D)           (None, 13, 13, 64)        18496
_________________________________________________________________
max_pooling2d_20 (MaxPooling (None, 6, 6, 64)          0
_________________________________________________________________
conv2d_31 (Conv2D)           (None, 4, 4, 64)          36928
_________________________________________________________________
flatten_10 (Flatten)         (None, 1024)              0
_________________________________________________________________
dense_22 (Dense)             (None, 64)                65600
_________________________________________________________________
dense_23 (Dense)             (None, 10)                650
=================================================================
Total params: 123,626
Trainable params: 123,626
Non-trainable params: 0
_________________________________________________________________
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_results</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">model_10</span><span class="p">,</span><span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1/10
62/62 [==============================] - 7s 99ms/step - loss: 1.7246 - accuracy: 0.2525 - val_loss: 1.4087 - val_accuracy: 0.4083
Epoch 2/10
62/62 [==============================] - 6s 89ms/step - loss: 1.3669 - accuracy: 0.4337 - val_loss: 1.1593 - val_accuracy: 0.5354
Epoch 3/10
62/62 [==============================] - 5s 88ms/step - loss: 1.1349 - accuracy: 0.5417 - val_loss: 1.0649 - val_accuracy: 0.5698
Epoch 4/10
62/62 [==============================] - 5s 88ms/step - loss: 1.0679 - accuracy: 0.5667 - val_loss: 0.9968 - val_accuracy: 0.5948
Epoch 5/10
62/62 [==============================] - 5s 88ms/step - loss: 0.9586 - accuracy: 0.6105 - val_loss: 0.9860 - val_accuracy: 0.6031
Epoch 6/10
62/62 [==============================] - 6s 91ms/step - loss: 0.9584 - accuracy: 0.6011 - val_loss: 0.9101 - val_accuracy: 0.6323
Epoch 7/10
62/62 [==============================] - 6s 91ms/step - loss: 0.8579 - accuracy: 0.6338 - val_loss: 0.9236 - val_accuracy: 0.6385
Epoch 8/10
62/62 [==============================] - 6s 91ms/step - loss: 0.8285 - accuracy: 0.6635 - val_loss: 0.8857 - val_accuracy: 0.6375
Epoch 9/10
62/62 [==============================] - 6s 96ms/step - loss: 0.8070 - accuracy: 0.6590 - val_loss: 0.8436 - val_accuracy: 0.6417
Epoch 10/10
62/62 [==============================] - 6s 97ms/step - loss: 0.7463 - accuracy: 0.7021 - val_loss: 0.8565 - val_accuracy: 0.6385
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot_train_results</span><span class="p">(</span><span class="n">train_results</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="assets/images/output_86_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_results</span><span class="p">(</span><span class="n">model_10</span><span class="p">,</span><span class="n">test_df</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>20/20 - 2s - loss: 0.9254 - accuracy: 0.6235
=====================
Test loss: 0.93
Test accuracy: 62.35%
=====================
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">initializer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">initializers</span><span class="p">.</span><span class="n">glorot_normal</span><span class="p">()</span>

<span class="n">model_11</span> <span class="o">=</span> <span class="n">models</span><span class="p">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model_11</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
<span class="n">model_11</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">))</span>
<span class="n">model_11</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">model_11</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
<span class="n">model_11</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">MaxPooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)))</span>
<span class="n">model_11</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
<span class="n">model_11</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Flatten</span><span class="p">())</span>
<span class="n">model_11</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
<span class="n">model_11</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'softmax'</span><span class="p">))</span>
<span class="n">model_11</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span>
                 <span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span>
                 <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
<span class="n">model_11</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Model: "sequential_11"
_________________________________________________________________
Layer (type)                 Output Shape              Param ##
=================================================================
conv2d_32 (Conv2D)           (None, 30, 30, 32)        896
_________________________________________________________________
dense_24 (Dense)             (None, 30, 30, 32)        1056
_________________________________________________________________
max_pooling2d_21 (MaxPooling (None, 15, 15, 32)        0
_________________________________________________________________
conv2d_33 (Conv2D)           (None, 13, 13, 64)        18496
_________________________________________________________________
max_pooling2d_22 (MaxPooling (None, 6, 6, 64)          0
_________________________________________________________________
conv2d_34 (Conv2D)           (None, 4, 4, 64)          36928
_________________________________________________________________
flatten_11 (Flatten)         (None, 1024)              0
_________________________________________________________________
dense_25 (Dense)             (None, 64)                65600
_________________________________________________________________
dense_26 (Dense)             (None, 10)                650
=================================================================
Total params: 123,626
Trainable params: 123,626
Non-trainable params: 0
_________________________________________________________________
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_results</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">model_11</span><span class="p">,</span><span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1/10
62/62 [==============================] - 6s 95ms/step - loss: 1.7334 - accuracy: 0.2922 - val_loss: 1.5436 - val_accuracy: 0.3406
Epoch 2/10
62/62 [==============================] - 5s 85ms/step - loss: 1.4169 - accuracy: 0.4048 - val_loss: 1.2417 - val_accuracy: 0.4906
Epoch 3/10
62/62 [==============================] - 5s 85ms/step - loss: 1.1794 - accuracy: 0.5382 - val_loss: 1.1026 - val_accuracy: 0.5740
Epoch 4/10
62/62 [==============================] - 5s 85ms/step - loss: 1.0718 - accuracy: 0.5650 - val_loss: 1.0383 - val_accuracy: 0.5750
Epoch 5/10
62/62 [==============================] - 5s 83ms/step - loss: 0.9770 - accuracy: 0.6016 - val_loss: 0.9818 - val_accuracy: 0.5885
Epoch 6/10
62/62 [==============================] - 5s 82ms/step - loss: 0.8958 - accuracy: 0.6272 - val_loss: 0.9418 - val_accuracy: 0.6104
Epoch 7/10
62/62 [==============================] - 5s 83ms/step - loss: 0.8910 - accuracy: 0.6301 - val_loss: 0.8858 - val_accuracy: 0.6406
Epoch 8/10
62/62 [==============================] - 5s 88ms/step - loss: 0.8430 - accuracy: 0.6491 - val_loss: 0.9028 - val_accuracy: 0.6344
Epoch 9/10
62/62 [==============================] - 6s 94ms/step - loss: 0.7978 - accuracy: 0.6708 - val_loss: 0.9324 - val_accuracy: 0.6375
Epoch 10/10
62/62 [==============================] - 6s 93ms/step - loss: 0.7712 - accuracy: 0.6818 - val_loss: 0.8450 - val_accuracy: 0.6781
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot_train_results</span><span class="p">(</span><span class="n">train_results</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="assets/images/output_90_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_results</span><span class="p">(</span><span class="n">model_11</span><span class="p">,</span><span class="n">test_df</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>20/20 - 2s - loss: 0.9435 - accuracy: 0.6363
=====================
Test loss: 0.94
Test accuracy: 63.63%
=====================
</code></pre></div></div>

<h3 id="conclusion">Conclusion</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    1. The model is trained with epochs of 15 initially but repeated training of the model in the running kernel makes the model overfit the data and could result in fake accuracies.
    2. With hyperparameter tuning, the model is improved by initialising with Xavier Glorot Initialization namely Xavier Uniform and Xavier Gaussian.
    3. It has been observed that the model performed with other loss functions and optimisers but could yield better results with appropriate batch size
    4. Meanwhile, it is also concluded that using different layers and adding more layers in the model would only increase the comkplexity but not improve the accuray unless an appropriate activation function is given.
    3. Later, the model is tuned with various epochs and batch_size to improve accuracy.
    4. Finally, the CNN gave the maximum accuracy of 68% with initial relu activation function and adam optimiser and no initialization and SparseCategoricalCrossEntropy as the best loss function.
</code></pre></div></div>

<h2 id="author">Author</h2>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Mahesh Kumar Badam Venkata
Master of Science in Applied Data Science
Syracuse University, Syracuse, NY
</code></pre></div></div>

<h2 id="citation">Citation</h2>

<p><strong>References:</strong></p>

<ol>
  <li>
    <p>ADL (24 April 2018), “<em>An intuitive guide to Convolutional Neural Networks</em>” retrieved from https://www.freecodecamp.org/news/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050/</p>
  </li>
  <li>
    <p>TensorFlow Tutorials,”<em>Convolutional Neural Network (CNN)</em>” retrieved from https://www.tensorflow.org/tutorials/images/cnn</p>
  </li>
  <li>
    <p>Analytics Vidhya Courses, “<em>Convolutional Neural Networks (CNN) from Scratch</em>” retrieved from https://courses.analyticsvidhya.com/courses/take/convolutional-neural-networks-cnn-from-scratch/texts/10844923-what-is-a-neural-network</p>
  </li>
  <li>
    <p>TensorFlow Core Documentation, “<em>Module: tf.keras.initializers</em>” retrieved from  https://www.tensorflow.org/api_docs/python/tf/keras/initializers?version=nightly</p>
  </li>
</ol>

<h2 id="licensing">Licensing</h2>

<p>MIT License</p>

<p>Copyright (c) 2020 Mahesh Kumar Badam Venkata</p>

<p>Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the “Software”), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:</p>

<p>The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.</p>

<p>THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
&lt;/p&gt;</p>

                
            </section>

            <footer class="page__meta">
                
                
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#cnn" class="page__taxonomy-item" rel="tag">CNN</a><span class="sep">, </span>
    
      <a href="/tags/#tensorflow" class="page__taxonomy-item" rel="tag">TensorFlow</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#deeplearning" class="page__taxonomy-item" rel="tag">DeepLearning</a>
    
    </span>
  </p>


                
  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2021-03-30T00:00:00-04:00">March 30, 2021</time></p>


            </footer>

            <section class="page__share">
  

  <a href="https://twitter.com/intent/tweet?text=How+to+classify+ship+images+with+Deep+Learning%20http%3A%2F%2Flocalhost%3A4000%2Fdeeplearning%2FCNNUsingTensorFlow%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Flocalhost%3A4000%2Fdeeplearning%2FCNNUsingTensorFlow%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2Fdeeplearning%2FCNNUsingTensorFlow%2F" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


            
  <nav class="pagination">
    
      <a href="#" class="pagination--pager disabled">Previous</a>
    
    
      <a href="/textmining/MultinomialNB_sentiment_fake/" class="pagination--pager" title="Multinomial Naive Bayes for Sentiment Analysis and Fake Review Detection
">Next</a>
    
  </nav>

        </div>

        
    </article>

    
    
    <div class="page__related">
        <h4 class="page__related-title">You May Also Enjoy</h4>
        <div class="grid__wrapper">
            
            



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/textmining/MultinomialNB_sentiment_fake/" rel="permalink">Multinomial Naive Bayes for Sentiment Analysis and Fake Review Detection
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          4 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">We often see text from the internet automatically classified as positive, negative and in websites like Amazon, they automatically track fake reviews and rem...</p>
  </article>
</div>

            
        </div>
    </div>
    
    
</div>
    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2021 Mahesh Badam. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>










  </body>
</html>
