<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.22.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Multinomial Naive Bayes for Sentiment Analysis and Fake Review Detection -</title>
<meta name="description" content="Multinomial Naive Bayes for Sentiment Analysis and Fake Review Detection">


  <meta name="author" content="Mahesh Badam">
  
  <meta property="article:author" content="Mahesh Badam">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="">
<meta property="og:title" content="Multinomial Naive Bayes for Sentiment Analysis and Fake Review Detection">
<meta property="og:url" content="http://localhost:4000/textmining/MultinomialNB_sentiment_fake/">


  <meta property="og:description" content="Multinomial Naive Bayes for Sentiment Analysis and Fake Review Detection">







  <meta property="article:published_time" content="2021-03-30T00:00:00-04:00">





  

  


<link rel="canonical" href="http://localhost:4000/textmining/MultinomialNB_sentiment_fake/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Mahesh Badam",
      "url": "http://localhost:4000/"
    
  }
</script>






<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title=" Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css">

<!--[if IE]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->


    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/"><img src="/assets/images/site-logo.png" alt=""></a>
        
        <a class="site-title" href="/">
          
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/about/">About</a>
            </li><li class="masthead__menu-item">
              <a href="/projects/">Projects</a>
            </li><li class="masthead__menu-item">
              <a href="/categories/">Categories</a>
            </li><li class="masthead__menu-item">
              <a href="/tags/">Tags</a>
            </li><li class="masthead__menu-item">
              <a href="/resume/">Resume</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
    
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  
    <div class="author__avatar">
      
        <img src="/assets/images/My-Pic.jpg" alt="Mahesh Badam" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">Mahesh Badam</h3>
    
    
      <div class="author__bio" itemprop="description">
        <p>I’m a graduate student at Syracuse University majoring in Applied Data Science</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name">Syracuse, NY, USA</span>
        </li>
      

      
        
          
            <li><a href="mailto:maheshbadam945@gmail.com" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span></a></li>
          
        
          
        
          
        
          
        
          
            <li><a href="https://github.com/mbadamve" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
            <li><a href="https://linkedin.com/in/mahesh-badam" rel="nofollow noopener noreferrer"><i class="fab fa-linkedin" aria-hidden="true"></i><span class="label">LinkedIn</span></a></li>
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>



    <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
        
        <meta itemprop="headline" content="Multinomial Naive Bayes for Sentiment Analysis and Fake Review Detection">
        
        
        <meta itemprop="description"
            content="Multinomial Naive Bayes for Sentiment Analysis and Fake Review Detection">
        
        <meta itemprop="datePublished" content="2021-03-30T00:00:00-04:00">
        

        <div class="page__inner-wrap">
            
            <header>
                <h1 id="page-title" class="page__title" itemprop="headline">Multinomial Naive Bayes for Sentiment Analysis and Fake Review Detection
</h1>
                

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          18 minute read
        
      </span>
    
  </p>


            </header>
            

            <section class="page__content" itemprop="text">
                
                <aside class="sidebar__right ">
                    <nav class="toc">
                        <header>
                            <h4 class="nav__title"><i class="fas fa-clone"></i> Table of Contents</h4>
                        </header>
                        <ul class="toc__menu"><li><a href="#multinomial-naive-bayes-for-sentiment-analysis-and-fake-review-detection">Multinomial Naive Bayes for Sentiment Analysis and Fake Review Detection</a><ul><li><a href="#sentiment-analysis">Sentiment Analysis</a><ul><li><a href="#first-step-is-to-import-required-libraries">First step is to import required libraries</a></li><li><a href="#model-interpretation-sentiment-analysis">Model Interpretation (Sentiment Analysis)</a></li><li><a href="#error-analysis">Error Analysis</a></li><li><a href="#top-features-contributing-to-the-classes">Top Features contributing to the classes</a></li></ul></li><li><a href="#fake-review-detection">Fake Review Detection</a><ul><li><a href="#model-interpretation-fake-review-detection">Model Interpretation (Fake Review Detection)</a></li><li><a href="#error-analysis-1">Error Analysis</a></li><li><a href="#top-features-contributing-to-the-classes-1">Top Features contributing to the classes</a></li></ul></li><li><a href="#author">Author</a></li></ul></li></ul>

                    </nav>
                </aside>
                
                <h3 id="multinomial-naive-bayes-for-sentiment-analysis-and-fake-review-detection">Multinomial Naive Bayes for Sentiment Analysis and Fake Review Detection</h3>

<p>We often see text from the internet automatically classified as positive, negative and in websites like Amazon, they automatically track fake reviews and remove them proactively to prevent bias for their text mining model. Althought they use complex and huge datasets for training process, the goal in this one is to analyse text data and interpret the models, find patterns in determining wrongly predicted text.</p>

<p>The dataset is provided by Prof. Bei Yu at Syracuse University. It is about a fake restaurant review data of true and fake reviews. Some were positive, and some were negative. It is completely fictional. It has columns ‘review’, ‘lie’, and ‘sentiment’ which are straight forward to understand. With this data, the goal is to create a cross validated Multinomial Naive Bayes Model trained on reviews, sentiment for <strong>Sentiment Analysis</strong> and reviews, lie for <strong>Fake Review Detection</strong></p>

<h4 id="sentiment-analysis">Sentiment Analysis</h4>
<h5 id="first-step-is-to-import-required-libraries">First step is to import required libraries</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Importing libaries
</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span><span class="p">,</span> <span class="n">TfidfVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">MultinomialNB</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_predict</span><span class="p">,</span> <span class="n">cross_validate</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Viewing sample data
# it is assumed that data is present in the relative path of this file
</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'deception_data_converted_final.tsv'</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">'</span><span class="se">\t</span><span class="s">'</span><span class="p">)</span>
<span class="n">train_data</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>lie</th>
      <th>sentiment</th>
      <th>review</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>f</td>
      <td>n</td>
      <td>'Mike\'s Pizza High Point, NY Service was very...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>f</td>
      <td>n</td>
      <td>'i really like this buffet restaurant in Marsh...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>f</td>
      <td>n</td>
      <td>'After I went shopping with some of my friend,...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>f</td>
      <td>n</td>
      <td>'Olive Oil Garden was very disappointing. I ex...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>f</td>
      <td>n</td>
      <td>'The Seven Heaven restaurant was never known f...</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Vectorizer options
</span>
<span class="n">unigram_bool_vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">encoding</span><span class="o">=</span><span class="s">'latin-1'</span><span class="p">,</span>
                                          <span class="n">binary</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                                          <span class="n">min_df</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                          <span class="n">stop_words</span><span class="o">=</span><span class="s">'english'</span><span class="p">)</span>

<span class="n">unigram_count_vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">encoding</span><span class="o">=</span><span class="s">'latin-1'</span><span class="p">,</span>
                                           <span class="n">binary</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                                           <span class="n">min_df</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                           <span class="n">stop_words</span><span class="o">=</span><span class="s">'english'</span><span class="p">)</span>

<span class="n">gram12_count_vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">encoding</span><span class="o">=</span><span class="s">'latin-1'</span><span class="p">,</span>
                                          <span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                                          <span class="n">min_df</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                          <span class="n">stop_words</span><span class="o">=</span><span class="s">'english'</span><span class="p">)</span>

<span class="n">unigram_tfidf_vectorizer</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">encoding</span><span class="o">=</span><span class="s">'latin-1'</span><span class="p">,</span>
                                           <span class="n">use_idf</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                                           <span class="n">min_df</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                           <span class="n">stop_words</span><span class="o">=</span><span class="s">'english'</span><span class="p">)</span>


<span class="c1"># Defining model for taking vectorizer options and print the cross validation metrics
</span><span class="k">def</span> <span class="nf">print_CV_MNB_results</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">vectorizers_list</span><span class="p">,</span> <span class="n">train_column</span><span class="p">,</span>
                         <span class="n">test_column</span><span class="p">,</span> <span class="n">k_for_CV</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="s">"""This function prints the confusion matrix, accuracy and the classification report of
    cross validation MultinomialNB model"""</span>
    <span class="k">global</span> <span class="n">X</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="n">train_column</span><span class="p">].</span><span class="n">values</span>
    <span class="k">global</span> <span class="n">y</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="n">test_column</span><span class="p">].</span><span class="n">values</span>

    <span class="k">global</span> <span class="n">nb_clf</span>
    <span class="n">nb_clf</span> <span class="o">=</span> <span class="n">MultinomialNB</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">vec</span> <span class="ow">in</span> <span class="n">vectorizers_list</span><span class="p">:</span>

        <span class="n">X_train_data_vec</span> <span class="o">=</span> <span class="n">vec</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">cv_pred</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">nb_clf</span><span class="p">,</span>
                                    <span class="n">X</span><span class="o">=</span><span class="n">X_train_data_vec</span><span class="p">,</span>
                                    <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
                                    <span class="n">cv</span><span class="o">=</span><span class="n">k_for_CV</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'=== Results using </span><span class="si">{</span><span class="n">vec</span><span class="si">}</span><span class="s"> as vectorizer ===</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'=== Confusion Matrix ==='</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">cv_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">))</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'========================'</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Accuracy: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">cv_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'========================'</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'Classification Report'</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">cv_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">labels</span><span class="p">))</span>
        <span class="k">print</span><span class="p">(</span>
            <span class="s">'====================================================================================='</span>
        <span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># creating a list of vectorizer types that we want to test
</span><span class="n">vectorizer_list</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">unigram_bool_vectorizer</span><span class="p">,</span>
    <span class="n">unigram_count_vectorizer</span><span class="p">,</span>
    <span class="n">gram12_count_vectorizer</span><span class="p">,</span>
    <span class="n">unigram_tfidf_vectorizer</span>
<span class="p">]</span>

<span class="c1"># Showing results for each vectorizer and model metrics
</span><span class="n">print_CV_MNB_results</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">vectorizer_list</span><span class="p">,</span> <span class="s">'review'</span><span class="p">,</span> <span class="s">'sentiment'</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span>
                     <span class="p">[</span><span class="s">'n'</span><span class="p">,</span> <span class="s">'p'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>=== Results using CountVectorizer(binary=True, encoding='latin-1', min_df=5, stop_words='english') as vectorizer ===

=== Confusion Matrix ===
[[32  6]
 [14 40]]
========================
Accuracy: 0.783
========================
Classification Report
              precision    recall  f1-score   support

           n       0.70      0.84      0.76        38
           p       0.87      0.74      0.80        54

    accuracy                           0.78        92
   macro avg       0.78      0.79      0.78        92
weighted avg       0.80      0.78      0.78        92

=====================================================================================
=== Results using CountVectorizer(encoding='latin-1', min_df=5, stop_words='english') as vectorizer ===

=== Confusion Matrix ===
[[33  5]
 [13 41]]
========================
Accuracy: 0.804
========================
Classification Report
              precision    recall  f1-score   support

           n       0.72      0.87      0.79        38
           p       0.89      0.76      0.82        54

    accuracy                           0.80        92
   macro avg       0.80      0.81      0.80        92
weighted avg       0.82      0.80      0.81        92

=====================================================================================
=== Results using CountVectorizer(encoding='latin-1', min_df=5, ngram_range=(1, 2),
                stop_words='english') as vectorizer ===

=== Confusion Matrix ===
[[33  5]
 [13 41]]
========================
Accuracy: 0.804
========================
Classification Report
              precision    recall  f1-score   support

           n       0.72      0.87      0.79        38
           p       0.89      0.76      0.82        54

    accuracy                           0.80        92
   macro avg       0.80      0.81      0.80        92
weighted avg       0.82      0.80      0.81        92

=====================================================================================
=== Results using TfidfVectorizer(encoding='latin-1', min_df=5, stop_words='english') as vectorizer ===

=== Confusion Matrix ===
[[33  6]
 [13 40]]
========================
Accuracy: 0.793
========================
Classification Report
              precision    recall  f1-score   support

           n       0.72      0.85      0.78        39
           p       0.87      0.75      0.81        53

    accuracy                           0.79        92
   macro avg       0.79      0.80      0.79        92
weighted avg       0.81      0.79      0.79        92

=====================================================================================
</code></pre></div></div>

<p>The Best Model for sentiment analysis task is the second one. The second and third, both have same accuracy and also other metrics. The difference between the vectorizers is one uses only unigrams and their counts for word representation while the latter one uses both unigrams and bigrams. Computationally speaking, model 2 with only unigram vectors is the best choice because of its less computation time for the task.</p>

<h5 id="model-interpretation-sentiment-analysis">Model Interpretation (Sentiment Analysis)</h5>

<p>Out of the four Vectorizers, the second and third have produced accuracy of 80%. So, if we analyse the results the model produce on the test set. If we understand properly, the Naive Bayes classifier is trained similarly for all the vectorizers. Only difference is the vector representation of the words. So, we need to understand which representation works better.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Viewing the predictions
# 'n' is for 0 and 'p' is for 1
</span>
<span class="n">nb_clf</span> <span class="o">=</span> <span class="n">MultinomialNB</span><span class="p">()</span>
<span class="n">vec</span> <span class="o">=</span> <span class="n">unigram_count_vectorizer</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="s">'review'</span><span class="p">]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="s">'sentiment'</span><span class="p">]</span>
<span class="n">X_train_data_vec</span> <span class="o">=</span> <span class="n">vec</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">nb_clf_cv</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">nb_clf</span><span class="p">,</span>
                                    <span class="n">X</span><span class="o">=</span><span class="n">X_train_data_vec</span><span class="p">,</span>
                                    <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span>
                                    <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">return_estimator</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># nb_clf_cv['estimator']
</span><span class="k">print</span><span class="p">(</span><span class="s">'Test Scores of Cross Validation'</span><span class="p">)</span>
<span class="n">test_scores</span> <span class="o">=</span> <span class="n">nb_clf_cv</span><span class="p">[</span><span class="s">'test_score'</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">test_scores</span><span class="p">,</span> <span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Model </span><span class="si">{</span><span class="n">test_scores</span><span class="p">.</span><span class="n">argmax</span><span class="p">()</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s"> is used for prediction </span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
<span class="n">cv_pred</span> <span class="o">=</span> <span class="n">nb_clf_cv</span><span class="p">[</span><span class="s">'estimator'</span><span class="p">][</span><span class="n">test_scores</span><span class="p">.</span><span class="n">argmax</span><span class="p">()].</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_data_vec</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Predictions'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">cv_pred</span><span class="p">[</span><span class="mi">10</span><span class="p">:</span><span class="mi">20</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Actual Values'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_train</span><span class="p">)[</span><span class="mi">10</span><span class="p">:</span><span class="mi">20</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Test Scores of Cross Validation
[0.84210526 0.89473684 0.72222222 0.83333333 0.72222222]

Model 2 is used for prediction

Predictions
['n' 'p' 'n' 'n' 'n' 'n' 'p' 'n' 'n' 'n']
Actual Values
['n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n']
</code></pre></div></div>

<p>Only two out of between 10 predictions are different than the original. This is not bad. So now we will see the wrongly predicted ones and think of why that would have happened.</p>

<h5 id="error-analysis">Error Analysis</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">err_cnt</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">print</span><span class="p">(</span><span class="s">'***************** Predicted is </span><span class="se">\'</span><span class="s">negative</span><span class="se">\'</span><span class="s"> but acutal is </span><span class="se">\'</span><span class="s">positive</span><span class="se">\'</span><span class="s"> ********************'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)):</span>
    <span class="k">if</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==</span><span class="s">'p'</span> <span class="ow">and</span> <span class="n">cv_pred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==</span><span class="s">'n'</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">err_cnt</span> <span class="o">=</span> <span class="n">err_cnt</span><span class="o">+</span><span class="mi">1</span>

<span class="k">print</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Type 2 errors:"</span><span class="p">,</span> <span class="n">err_cnt</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'***************************************************************************************'</span><span class="p">)</span>

<span class="k">print</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s">'***************** Predicted is </span><span class="se">\'</span><span class="s">positive</span><span class="se">\'</span><span class="s"> but acutal is </span><span class="se">\'</span><span class="s">negative</span><span class="se">\'</span><span class="s"> ********************'</span><span class="p">)</span>
<span class="n">err_cnt</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)):</span>
    <span class="k">if</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==</span><span class="s">'n'</span> <span class="ow">and</span> <span class="n">cv_pred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==</span><span class="s">'p'</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">err_cnt</span> <span class="o">=</span> <span class="n">err_cnt</span><span class="o">+</span><span class="mi">1</span>
<span class="k">print</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Type 1 errors:"</span><span class="p">,</span> <span class="n">err_cnt</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'***************************************************************************************'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>***************** Predicted is 'negative' but acutal is 'positive' ********************
'Ruby Tuesday is my favorite America Style Restaurant. The salad is awesome. And I like the baby pork ribs so much . So does the coconut shrimp.'
?
?
'Can\'t say too much about it. Just, try it buddy!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!You\'ll regret if you don\'t.'

Type 2 errors: 4
***************************************************************************************

***************** Predicted is 'positive' but acutal is 'negative' ********************
'Mike\'s Pizza High Point, NY Service was very slow and the quality was low. You would think they would know at least how to make good pizza, not. Stick to pre-made dishes like stuffed pasta or a salad. You should consider dining else where.'
'i really like this buffet restaurant in Marshall street. they have a lot of selection of american, japanese, and chinese dishes. we also got a free drink and free refill. there are also different kinds of dessert. the staff is very friendly. it is also quite cheap compared with the other restaurant in syracuse area. i will definitely coming back here.'
'I once went to Chipotle at Marshall Street to have my dinner. The experience is horrible!!! When I began to order, I found that there were no steak and chicken! But I want to have the steak burrito! How can a Chipotle have no steak and chicken! What\'s worse, there is no sauce! No any kind of sauce! I can\'t believe my eyes! I will never go to the Chipotle at Marshall Street with my little friends any more!'
'I went there with two friends at 6pm. Long queue was there. But it didn\'t take us long to wait. The waiter was nice but worked in a hurry. We ordered \'Today\'s Special\', some drinks and two icecreams. I had a steak, a little bit too salty, but acceptable. My friends didn\'t like their lamb chop and cod filet that much. It costed us almost $100. Not worth it. Will not visit there any more.'
'Pizza Hut Syracuse, NY The only thing worth going here for is the lunch salad bar. The decor is very dated and the pizza is GREESY. Tables and bathroom are dirty. Waitstaff seem to have low expectations of service.'
'Last week, I went o my favorite Indian \'Thali\' place in Jersey City. I have been there before and have loved the variety of Indian offerings they have in their buffet. However, last time, the number of delicacies were limited and to top it up, they were stale. It felt like they used the same items from the previous day. I was utterly disappointed by the quality of food at one of my favorite Indian restaurant in Jersey City.'
'This place used to be great. I can\'t believe it\'s current state. Instead of the cool, dimly-lit lounge that I was used to, I was in a cheap, smelly bar. The music has no soul, the bartender is mean. This place no longer exudes a welcoming spirit. The crowd is awkward and old. I want my old hangout back!!'
'I have been to a Asian restaurant in New York city. The menu is written by Chinese and English. When I choose a famous chinses plate called Gongbao chicken, I was surprised. The taste of it like a Thai flavor, which is cooked by curry. '

Type 1 errors: 8
***************************************************************************************
</code></pre></div></div>

<p>In the above, we can see the two different types of errors. It can be thought like sometimes when there are new words in the comment, then we can say model will tend to choose wrong category. When more words appear in one category then it is related that people use those in a particular emotion. Now, we need to see which features in the model are the top for making prediction decision</p>

<h5 id="top-features-contributing-to-the-classes">Top Features contributing to the classes</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Top features
</span>

<span class="n">log_prob</span> <span class="o">=</span> <span class="n">nb_clf_cv</span><span class="p">[</span><span class="s">'estimator'</span><span class="p">][</span><span class="n">test_scores</span><span class="p">.</span><span class="n">argmax</span><span class="p">()].</span><span class="n">feature_log_prob_</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">log_prob</span><span class="p">)):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'Coeffients of features sorted in the descending order for negative class'</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'Coeffients of features sorted in the descending order for positive class'</span><span class="p">)</span>
    <span class="n">sorted_log_prob_10</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">log_prob</span><span class="p">[</span><span class="n">i</span><span class="p">])[</span><span class="o">-</span><span class="mi">10</span><span class="p">:]</span>
    <span class="k">print</span><span class="p">(</span><span class="n">log_prob</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">sorted_log_prob_10</span><span class="p">])</span>

    <span class="k">print</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'====== Top features for negative sentiment category ======'</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'====== Top features for positive sentiment category ======'</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">sorted_log_prob_10</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">vec</span><span class="p">.</span><span class="n">vocabulary_</span><span class="p">.</span><span class="n">items</span><span class="p">())[</span><span class="n">x</span><span class="p">])</span>
    <span class="k">print</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Coeffients of features sorted in the descending order for negative class
[-4.05415368 -4.05415368 -3.8870996  -3.8870996  -3.67946023 -3.67946023
 -3.45631668 -3.27399512 -2.84113104 -2.84113104]

====== Top features for negative sentiment category ======
('people', 64)
('special', 81)
('favorite', 32)
('ordered', 61)
('wasn', 94)
('fresh', 34)
('ask', 3)
('want', 93)
('order', 60)
('taste', 84)

Coeffients of features sorted in the descending order for positive class
[-3.94931879 -3.94931879 -3.85400861 -3.85400861 -3.76699723 -3.61284655
 -3.3074649  -3.16086143 -2.78616798 -2.75539632]

====== Top features for positive sentiment category ======
('family', 31)
('special', 81)
('lunch', 51)
('want', 93)
('high', 41)
('favorite', 32)
('place', 66)
('pasta', 63)
('order', 60)
('taste', 84)
</code></pre></div></div>

<p>The downside of the top features is that both classs have a few common features that contribute for making predictions.</p>

<h4 id="fake-review-detection">Fake Review Detection</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># creating a list of vectorizer types that we want to test
</span><span class="n">vectorizer_list</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">unigram_bool_vectorizer</span><span class="p">,</span> <span class="n">unigram_count_vectorizer</span><span class="p">,</span> <span class="n">gram12_count_vectorizer</span><span class="p">,</span>
    <span class="n">unigram_tfidf_vectorizer</span>
<span class="p">]</span>

<span class="c1"># Showing results for each vectorizer and model metrics
</span>
<span class="n">print_CV_MNB_results</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">vectorizer_list</span><span class="p">,</span> <span class="s">'review'</span><span class="p">,</span> <span class="s">'lie'</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span>
                     <span class="p">[</span><span class="s">'f'</span><span class="p">,</span> <span class="s">'t'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>=== Results using CountVectorizer(binary=True, encoding='latin-1', min_df=5, stop_words='english') as vectorizer ===

=== Confusion Matrix ===
[[27 19]
 [19 27]]
========================
Accuracy: 0.587
========================
Classification Report
              precision    recall  f1-score   support

           f       0.59      0.59      0.59        46
           t       0.59      0.59      0.59        46

    accuracy                           0.59        92
   macro avg       0.59      0.59      0.59        92
weighted avg       0.59      0.59      0.59        92

=====================================================================================
=== Results using CountVectorizer(encoding='latin-1', min_df=5, stop_words='english') as vectorizer ===

=== Confusion Matrix ===
[[26 19]
 [20 27]]
========================
Accuracy: 0.576
========================
Classification Report
              precision    recall  f1-score   support

           f       0.57      0.58      0.57        45
           t       0.59      0.57      0.58        47

    accuracy                           0.58        92
   macro avg       0.58      0.58      0.58        92
weighted avg       0.58      0.58      0.58        92

=====================================================================================
=== Results using CountVectorizer(encoding='latin-1', min_df=5, ngram_range=(1, 2),
                stop_words='english') as vectorizer ===

=== Confusion Matrix ===
[[27 17]
 [19 29]]
========================
Accuracy: 0.609
========================
Classification Report
              precision    recall  f1-score   support

           f       0.59      0.61      0.60        44
           t       0.63      0.60      0.62        48

    accuracy                           0.61        92
   macro avg       0.61      0.61      0.61        92
weighted avg       0.61      0.61      0.61        92

=====================================================================================
=== Results using TfidfVectorizer(encoding='latin-1', min_df=5, stop_words='english') as vectorizer ===

=== Confusion Matrix ===
[[26 20]
 [20 26]]
========================
Accuracy: 0.565
========================
Classification Report
              precision    recall  f1-score   support

           f       0.57      0.57      0.57        46
           t       0.57      0.57      0.57        46

    accuracy                           0.57        92
   macro avg       0.57      0.57      0.57        92
weighted avg       0.57      0.57      0.57        92

=====================================================================================
</code></pre></div></div>

<p>The best model for fake review detection is the third one that uses both unigrams and bigrams. The accuracy reported is almost 61%. We should understand that one model is not suitable for all and also one type of word representation is not suitable for all types of data. Depending on the type of data available the preprocessing of the words changes, and, in this case, bigrams are also important to perform fake review detection. We often see a pattern of words in fake reviews. Hence, maybe it is because bigrams and trigrams may also become useful to predict the review authenticity.</p>

<h5 id="model-interpretation-fake-review-detection">Model Interpretation (Fake Review Detection)</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Viewing the predictions
# 'f' is for 0 and 't' is for 1
</span>
<span class="n">nb_clf</span> <span class="o">=</span> <span class="n">MultinomialNB</span><span class="p">()</span>
<span class="n">vec</span> <span class="o">=</span> <span class="n">gram12_count_vectorizer</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="s">'review'</span><span class="p">]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="s">'lie'</span><span class="p">]</span>
<span class="n">X_train_data_vec</span> <span class="o">=</span> <span class="n">vec</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">nb_clf_cv</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">nb_clf</span><span class="p">,</span>
                                    <span class="n">X</span><span class="o">=</span><span class="n">X_train_data_vec</span><span class="p">,</span>
                                    <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span>
                                    <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">return_estimator</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># nb_clf_cv['estimator']
</span><span class="k">print</span><span class="p">(</span><span class="s">'Test Scores of Cross Validation'</span><span class="p">)</span>
<span class="n">test_scores</span> <span class="o">=</span> <span class="n">nb_clf_cv</span><span class="p">[</span><span class="s">'test_score'</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">test_scores</span><span class="p">,</span> <span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Model </span><span class="si">{</span><span class="n">test_scores</span><span class="p">.</span><span class="n">argmax</span><span class="p">()</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s"> is used for prediction </span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
<span class="n">cv_pred</span> <span class="o">=</span> <span class="n">nb_clf_cv</span><span class="p">[</span><span class="s">'estimator'</span><span class="p">][</span><span class="n">test_scores</span><span class="p">.</span><span class="n">argmax</span><span class="p">()].</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_data_vec</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Predictions'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">cv_pred</span><span class="p">[</span><span class="mi">10</span><span class="p">:</span><span class="mi">20</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Actual Values'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_train</span><span class="p">)[</span><span class="mi">10</span><span class="p">:</span><span class="mi">20</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Test Scores of Cross Validation
[0.57894737 0.73684211 0.55555556 0.61111111 0.55555556]

Model 2 is used for prediction

Predictions
['f' 'f' 't' 'f' 'f' 't' 'f' 'f' 'f' 'f']
Actual Values
['f' 'f' 'f' 'f' 'f' 'f' 'f' 'f' 'f' 'f']
</code></pre></div></div>

<p>Only one out of between 10 predictions are different than the original. This is not bad. So now we will see the wrongly predicted ones and think of why that would have happened.</p>

<h5 id="error-analysis-1">Error Analysis</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">err_cnt</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">print</span><span class="p">(</span><span class="s">'************ Predicted is </span><span class="se">\'</span><span class="s">True</span><span class="se">\'</span><span class="s"> but acutal is </span><span class="se">\'</span><span class="s">False</span><span class="se">\'</span><span class="s"> for fake review? question ***********'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)):</span>
    <span class="k">if</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==</span><span class="s">'f'</span> <span class="ow">and</span> <span class="n">cv_pred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==</span><span class="s">'t'</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">err_cnt</span> <span class="o">=</span> <span class="n">err_cnt</span><span class="o">+</span><span class="mi">1</span>

<span class="k">print</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Type 2 errors:"</span><span class="p">,</span> <span class="n">err_cnt</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'***************************************************************************************'</span><span class="p">)</span>

<span class="k">print</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s">'************ Predicted is </span><span class="se">\'</span><span class="s">False</span><span class="se">\'</span><span class="s"> but acutal is </span><span class="se">\'</span><span class="s">True</span><span class="se">\'</span><span class="s"> for fake review? question ***********'</span><span class="p">)</span>
<span class="n">err_cnt</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)):</span>
    <span class="k">if</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==</span><span class="s">'t'</span> <span class="ow">and</span> <span class="n">cv_pred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">==</span><span class="s">'f'</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">err_cnt</span> <span class="o">=</span> <span class="n">err_cnt</span><span class="o">+</span><span class="mi">1</span>

<span class="k">print</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Type 1 errors:"</span><span class="p">,</span> <span class="n">err_cnt</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'***************************************************************************************'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>************ Predicted is 'True' but acutal is 'False' for fake review? question ***********
'Yesterday, I went to a casino-restaurant called \'NoFreeDrinks\'. First, I thought its just a name but later at the blackjack table, when I ordered a attendant to get me a round of Jack and Coke, instead of saying \'Yeah sure\', the attendant said $6. It is preposterous. I have never paid for my drinks at the casino. Clearly, the casino does not understand that the more the people drink, the more they will loose. Someone needs to teach the casino how to do business.'
'I entered the restaurant and a waitress came by with a blanking looking and threw the menu on the table, said coldly, help yourself. Then she just disappeared, I waited and waited, but no one even notice me until I went directly to the front desk to order the food. Long time later, I finally had the most terrible food in my life and even found an flyer in my plate. I refused to give the tips and the waitress began to get angry and rudely walk away. This is the most terrible experience that I will never forget. '
'In each of the diner dish there are at least one fly in it. We are waiting for an hour for the dish cooked done. The taste reminds me of a smell that I never want to try any more, and when the food is in the mouth, it could be a nightmare that I really want to wake up. The attitude of waiters is bad enough that I don\'t want to step in to this restaurant again.'
'In my favorite restaurant Yuenan Restaurant. The noodle with beef is the best noodle in this area. I love it so much and so do my friends.'
'This restaurant is AMAZING! I felt like life was worth living again when I bit into the carmelized onion tofurky extravaganzaburger. I highly reccommend going here for delicious food, fun atmosphere, and decent prices. Vegetarian cusine=really good.'
'I went to this ultra-luxurious restaurant in Downtown New York which is known for its exotic and expensive cuisine. I had a glass of champagne along with very expensive Caviar. I had a delicious Chicken Pasta cooked in white sauce. This was followed by mouth melting chocolate brownie and vanilla ice cream. The service standards were superlative and I felt special visiting this restaurant. '
'This restaurant ROCKS! I mean the food is great and people are great. Everything is great great just great!!! I love it. I like it. '
'Two days ago, I went to the rooftop restaurant in NYC that served brunch. it was one of the best brunch that I have ever had. The view from the table was serene and I could see both the the Hudson River and the East River with outstanding views of Empire State Building, the Chryslers tower, Freedom tower and the Central park. A great place with great food and a perplexing view'
'I went into the restaurant, it decorated comfortably with a soft light and nice pictures, the waitress was kind and stand by my side throughout the whole dining time, asking whether I need something more and kept smiling. '
'The service is good and I just felt like home. Waitresses and waiters always ask me want to I need and how about the taste, in order to bring m ore good menu and service for us to enjoy. And there is also music from the lobby, someones are dancing in the middle.'

Type 2 errors: 10
***************************************************************************************

************ Predicted is 'False' but acutal is 'True' for fake review? question ***********
'Friday is the worse restaurant I have ever gone. Each of the dishes we ordered is quite terrible. We did not finish any of them.'
'The restaurant environment is bad and I can see flies everywhere. The dishes are not that bad to taste, neither not that good. We discovered two flies in the dishes which I really cannot bear.'
'This restaurant is quite popular recently. Went there with two of my friends at 6pm, really long queue. We waited for almost 90 minutes to be seated. Seats were narrow. It was too easy to hear clearly what your neighbors were talking about. The waitress was so impatient that we were wondering whether she didn\'t get paid. Food was so so. No idea why it\'s so popular. Never be back again.'
'We indians are craving Indian food around the university campus. The first time I went to Samrat, i was very excited to taste all the dishes that were served in the buffet. As i started eating I found every was somehow tasting similar. The Bengan Bharta was sweet and gulab jaam were canned and not made freshly. To add to it the food was made with baking soda so that it filled our stomach quickly. '
'Stronghearts cafe is the BEST! The owners have a great ethic, and the food is TO DIE FOR. I had a pumpkin espresso milkshake, named after Albert Einstein, and it was only $5! #winning The food, though vegan, is amazing because of the fresh ingredients and presentation. Speed of service is great too. They have reading material, wifi, and many tables of different types depending on whether you are with friends or by yourself doing homework. YEAH!'
?
?
'Can\'t say too much about it. Just, try it buddy!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!You\'ll regret if you don\'t.'
'My sister and I ate at this restaurant called Matador. The overall look and ambiance of the restaurant was very appealing. We first ordered strawberry margaritas--which were really good.Then my sister ordered a spinach lasagna with Alfredo sauce and I ordered Pasta ravioli with marinara sauce. My sister and I unanimously agreed they were the best pastas we had ever had. It was a beautiful blend of flavors which complimented each other. I would totally recommend Matador and it was an overall amazing experience.'

Type 1 errors: 9
***************************************************************************************
</code></pre></div></div>

<p>If you see the pattern in the fake reviews, they are slightly short in the length of the review and
irregular usage of characters, there only the reader knows they are fake reviews because the story or the emotion in the sentences do not connect and can be thought they are quite imaginary. One solution can be to have data, because more text with the similar pattern can improve the model.</p>

<h5 id="top-features-contributing-to-the-classes-1">Top Features contributing to the classes</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Top features
</span>
<span class="n">log_prob</span> <span class="o">=</span> <span class="n">nb_clf_cv</span><span class="p">[</span><span class="s">'estimator'</span><span class="p">][</span><span class="n">test_scores</span><span class="p">.</span><span class="n">argmax</span><span class="p">()].</span><span class="n">feature_log_prob_</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">log_prob</span><span class="p">)):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'Coeffients of features sorted in the descending order for not a fake review class'</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'Coeffients of features sorted in the descending order for fake review class'</span><span class="p">)</span>
    <span class="n">sorted_log_prob_10</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">log_prob</span><span class="p">[</span><span class="n">i</span><span class="p">])[</span><span class="o">-</span><span class="mi">10</span><span class="p">:]</span>
    <span class="k">print</span><span class="p">(</span><span class="n">log_prob</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">sorted_log_prob_10</span><span class="p">])</span>

    <span class="k">print</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'====== Top features for not a fake review category ======'</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'====== Top features for fake review category ======'</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">sorted_log_prob_10</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">vec</span><span class="p">.</span><span class="n">vocabulary_</span><span class="p">.</span><span class="n">items</span><span class="p">())[</span><span class="n">x</span><span class="p">])</span>
    <span class="k">print</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Coeffients of features sorted in the descending order for not a fake review class
[-3.952845   -3.87280229 -3.87280229 -3.87280229 -3.79869432 -3.72970145
 -3.66516293 -3.49331267 -3.00376445 -2.94124409]

====== Top features for not a fake review category ======
('friends', 38)
('worst', 98)
('hard', 42)
('hour', 45)
('sauce', 79)
('ask', 4)
('special', 83)
('salad', 78)
('taste', 86)
('bad', 7)

Coeffients of features sorted in the descending order for fake review class
[-4.09434456 -4.09434456 -3.80666249 -3.80666249 -3.72661978 -3.65251181
 -3.51898042 -3.4583558  -2.82583324 -2.7080502 ]

====== Top features for fake review category ======
('special', 83)
('dish', 28)
('hour', 45)
('ask', 4)
('friends', 38)
('salad', 78)
('sauce', 79)
('dine', 24)
('bad', 7)
('taste', 86)
</code></pre></div></div>

<p>In this model too, there is an overlap of true and fake review top classes, and the fake reviews are near real to the true fake review and our model is doing its best in identifying fake reviews inspite of them being fake reviews.</p>

<h4 id="author">Author</h4>

<p><em>Mahesh Kumar Badam Venkata <br />
  Master of Science in Applied Data Science<br />
  Syracuse University, Syracuse, NY</em></p>

                
            </section>

            <footer class="page__meta">
                
                
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#crossvalidation" class="page__taxonomy-item" rel="tag">CrossValidation</a><span class="sep">, </span>
    
      <a href="/tags/#fakereviewdetection" class="page__taxonomy-item" rel="tag">FakeReviewDetection</a><span class="sep">, </span>
    
      <a href="/tags/#multinomialnb" class="page__taxonomy-item" rel="tag">MultinomialNB</a><span class="sep">, </span>
    
      <a href="/tags/#python" class="page__taxonomy-item" rel="tag">Python</a><span class="sep">, </span>
    
      <a href="/tags/#sentimentanalysis" class="page__taxonomy-item" rel="tag">SentimentAnalysis</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#textmining" class="page__taxonomy-item" rel="tag">TextMining</a>
    
    </span>
  </p>


                
  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2021-03-30T00:00:00-04:00">March 30, 2021</time></p>


            </footer>

            <section class="page__share">
  

  <a href="https://twitter.com/intent/tweet?text=Multinomial+Naive+Bayes+for+Sentiment+Analysis+and+Fake+Review+Detection%20http%3A%2F%2Flocalhost%3A4000%2Ftextmining%2FMultinomialNB_sentiment_fake%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Flocalhost%3A4000%2Ftextmining%2FMultinomialNB_sentiment_fake%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2Ftextmining%2FMultinomialNB_sentiment_fake%2F" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


            
  <nav class="pagination">
    
      <a href="/deeplearning/CNNUsingTensorFlow/" class="pagination--pager" title="How to classify ship images with Deep Learning
">Previous</a>
    
    
      <a href="#" class="pagination--pager disabled">Next</a>
    
  </nav>

        </div>

        
    </article>

    
    
    <div class="page__related">
        <h4 class="page__related-title">You May Also Enjoy</h4>
        <div class="grid__wrapper">
            
            



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/deeplearning/CNNUsingTensorFlow/" rel="permalink">How to classify ship images with Deep Learning
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          31 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">The goal of this project is to create a Deep Learning model using Convolutional Neural Networks. The dataset consists of images of 5 types of ships which are...</p>
  </article>
</div>

            
        </div>
    </div>
    
    
</div>
    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2021 Mahesh Badam. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>










  </body>
</html>
